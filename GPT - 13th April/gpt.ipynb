{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6daeaa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d0dc80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"my name is sudhanshu kumar , i work with euron , Helping Millions of Students Succeed Sudhanshu's commitment to affordable education wasn't just a business strategy—it was his life's mission. Over the years, iNeuron has helped over 1.5 million students from 34+ countries, providing them with the skills they need to succeed in today's competitive job market. Many of these students, like Sudhanshu himself, came from disadvantaged backgrounds. They saw iNeuron as a lifeline—an opportunity to rise above their circumstances.\\n\\nIn 2022, iNeuron was acquired by PhysicsWallah in a deal worth ₹250 crore. While this acquisition was a significant milestone, Sudhanshu remained focused on his mission. Even after the acquisition, iNeuron continued to offer some of the most affordable and accessible tech courses in the world. Helping Millions of Students Succeed Sudhanshu's commitment to affordable education wasn't just a business strategy—it was his life's mission. Over the years, iNeuron has helped over 1.5 million students from 34+ countries, providing them with the skills they need to succeed in today's competitive job market. Many of these students, like Sudhanshu himself, came from disadvantaged backgrounds. They saw iNeuron as a lifeline—an opportunity to rise above their circumstances.\\n\\nIn 2022, iNeuron was acquired by PhysicsWallah in a deal worth ₹250 crore. While this acquisition was a significant milestone, Sudhanshu remained focused on his mission. Even after the acquisition, iNeuron continued to offer some of the most affordable and accessible tech courses in the world.Sudhanshu Kumar's life is a story of triumph over adversity, driven by the belief in the transformative power of education. Born in Jamshedpur, Jharkhand, India, to a family of very modest means, Sudhanshu's early years were marked by financial hardship. His surroundings offered little opportunity, and resources were limited, yet he understood from a young age that education could be his ticket out of poverty.\\n\\nWhile many would have been daunted by the lack of support and opportunity, Sudhanshu was relentless in his pursuit of knowledge. He knew that education had the power to change lives, and he was determined to leverage it to create a better future for himself and his family. Despite the numerous challenges along the way, Sudhanshu excelled academically, eventually earning a degree in Computer Science and Engineering (CSE). After completing his education, Sudhanshu began his professional journey in the tech industry, working with prestigious companies like Wipro, Deloitte, Verizon Labs, and Ernst & Young. During this time, he gained expertise in various technologies and frameworks, including SAP WebDynpro, Fiori UI5 HANA, Java, Big Data, Data Analytics, and more. He became a well-rounded technologist, well-respected in his field.\\n\\nDespite his growing success, Sudhanshu never forgot his roots. He knew that there were many others who, like him, came from humble backgrounds and were looking for an opportunity to change their lives through education. It was during this time that Sudhanshu realized a harsh truth: quality education was often inaccessible to those who needed it the most. The high cost of education barred millions of people from pursuing their dreams, especially in tech fields that required specialized skills. Fueled by his passion for making education accessible, Sudhanshu decided to take action. In 2019, he founded iNeuron Intelligence Private Limited, an edtech platform that would make tech upskilling affordable and accessible for everyone. His mission was clear: to provide high-quality courses at a price so low that even those from the most disadvantaged backgrounds could afford to learn.\\n\\niNeuron was designed to be more than just an online learning platform. It offered a comprehensive bundle of resources, including courses, books, hands-on projects, and live classes, making sure that learners could gain real-world, applicable skills. Most importantly, iNeuron was priced to ensure no student would be left behind due to financial constraints.\\n\\nThe company quickly gained traction, thanks to Sudhanshu's focus on affordability and quality. In 2021, iNeuron raised $3 million in funding from S. Chand, a leading education publisher. This allowed iNeuron to expand its offerings and reach a larger audience. Building on the success of iNeuron, Sudhanshu is now leading Euron, a unified platform for tech upskilling. Euron is designed for enterprises, schools, colleges, government organizations, and individuals looking to improve their tech skills. The platform provides a comprehensive bundle of resources, including courses, books, live classes, and projects. Euron's unique offering is its ability to provide licenses at scale—organizations can subscribe to provide their teams with unlimited access to learning materials for just 1600 INR per year per license.\\n\\nFor individuals, Euron Plus offers a similar plan, priced at 2900 INR per year, giving learners access to all of Euron's content, along with 24/7 support through Euron Assist. The idea is simple: anyone, anywhere, should have the opportunity to upskill without financial barriers.\\n\\nThe Euron Motto: Education for All, Without Limits\\n\\nAt the heart of Euron's philosophy is a single, powerful idea: Education for All, Without Limits. Sudhanshu believes that every person deserves the chance to learn, grow, and succeed, regardless of their financial situation or background. This belief is what drives Euron's mission to make tech education not just affordable but also accessible to anyone, anywhere in the world.\\n\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"data.txt\", 'r', encoding = 'utf-8') as f:\n",
    "    text_data = f.read()\n",
    "text_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e5874d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=5000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts([text_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2598854",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = tokenizer.texts_to_sequences([text_data])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d88e18ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "860"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71519323",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tokenizer.pkl\",'wb') as f:\n",
    "    pickle.dump(tokenizer,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "901bfa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_set(seq,window_size = 100):\n",
    "    input, labels = [],[]\n",
    "    for i in range(len(seq)-window_size):\n",
    "        input.append(seq[i:i+window_size])\n",
    "        labels.append(seq[i+1:i+window_size+1])\n",
    "    return np.array(input), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a32d8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, y_data = create_data_set(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "263ada16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([158, 159,  16,   9, 160, 161, 162,  20,  21,  69,  49,   5,  22,\n",
       "        28,  36,  70,   2,  23,  10,  71,  29,   4,  72,  73,  12,   8,\n",
       "        74,  24,  30,   3,  50,  11,  75,  76,  30,  77,  78,  51,  22,\n",
       "        14,  79,  80,  81,  82,  20,   3,  31,  37,  83,   2,  28,   6,\n",
       "        84,  85,  86,  87,  38,   5,  88,  22,  39,   9,  52,  53,  14,\n",
       "        54,  40,  37,  89,  11,  90,   4,  91,  25,   2,  92,  93,  18,\n",
       "        94,   6,  95,  11,  12,  96,  26,  97,   6,   4,  98,  99, 100,\n",
       "       101,  55,  27,  41,  12,   4, 102, 103,   9])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c288514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([159,  16,   9, 160, 161, 162,  20,  21,  69,  49,   5,  22,  28,\n",
       "        36,  70,   2,  23,  10,  71,  29,   4,  72,  73,  12,   8,  74,\n",
       "        24,  30,   3,  50,  11,  75,  76,  30,  77,  78,  51,  22,  14,\n",
       "        79,  80,  81,  82,  20,   3,  31,  37,  83,   2,  28,   6,  84,\n",
       "        85,  86,  87,  38,   5,  88,  22,  39,   9,  52,  53,  14,  54,\n",
       "        40,  37,  89,  11,  90,   4,  91,  25,   2,  92,  93,  18,  94,\n",
       "         6,  95,  11,  12,  96,  26,  97,   6,   4,  98,  99, 100, 101,\n",
       "        55,  27,  41,  12,   4, 102, 103,   9, 104])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e171a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self,max_length,d_model):\n",
    "        super().__init__()\n",
    "        pos = np.arrange(max_length)[:,np.newaxis]\n",
    "        i = np.arrange(d_model)[np.newaxis,:]\n",
    "        angle_rates = 1/np.power(10000),(2*(i//2))/np.float32(d_model)\n",
    "        angle_rads = pos.angle_rates\n",
    "        angle_rads[:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4887b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_block(embed_dim , num_heads,ff_dim,dropout = .1):\n",
    "    input = layers.Input(shape=(None,embed_dim))\n",
    "    attn_output = layers.MultiHeadAttention(num_heads = num_heads ,key_dim = embed_dim)(input,input)\n",
    "    attn_output = layers.Droupout(dropout)(attn_output)\n",
    "    out1 = layers.LayerNormalization(epsilon = 1e-6)(input + attn_output)\n",
    "    \n",
    "    \n",
    "    ffn = tf.keras.Sequential([\n",
    "        layers.Dense(ff_dim,activation = 'relu'),\n",
    "        layers.Dense(embed_dim)\n",
    "    ])\n",
    "    \n",
    "    ffn_output = ffn(out1)\n",
    "    ffn_output = layers.Dropout(dropout)(ffn_output)\n",
    "    out2 = layers.LayerNormalization(epsilon = 1e-6)(out1+ffn_output)\n",
    "    return tf.keras.Model(input=input,outputs = out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84af54c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Euron Logo\n",
    "Plus\n",
    "\n",
    "Search courses, books, and more...\n",
    "9\n",
    "\n",
    "Chetan\n",
    "Current LLM IconNext LLM Icon\n",
    "\n",
    "Back\n",
    "class will start at 2.30 PM IST\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1:25:22\n",
    "/\n",
    "1:00:00\n",
    "\n",
    "Auto\n",
    "\n",
    "Auto\n",
    "\n",
    "\n",
    "\n",
    "Overview\n",
    "\n",
    "\n",
    "Q&A\n",
    "\n",
    "\n",
    "Reviews\n",
    "\n",
    "Generative AI\n",
    "\n",
    "Learn how to build, fine-tune, and deploy advanced AI models – From Basics to Industry-Level Applications! This beginner-friendly course is designed to equip you with hands-on expertise in Natural Language Processing (NLP), Large Language Models (LLMs), Generative AI, and cutting-edge frameworks like Hugging Face, OpenAI, LangChain, LlamaIndex, and Vector Databases. You will work on real-world AI applications such as AI-powered chatbots, RAG-based search systems, multimodal AI applications, and fine-tuning of state-of-the-art LLMs like GPT, LLaMA, and Mistral.\n",
    "\n",
    "Read more\n",
    "Boktiar Ahmed Bappy\n",
    "Data Science | Generative AI | Neural Network | Machine Learning | Deep Learning\n",
    "profile image\n",
    "I am Boktiar Ahmed Bappy, a Data Scientist and dedicated mentor with four years of experience transforming complex business challenges into actionable solutions using advanced AI techniques. My expertise spans multiple domains in Python, Machine Learning, Deep Learning, MLOps, Generative AI, a...\n",
    "\n",
    "Show more\n",
    "\n",
    "Course Content\n",
    "\n",
    "\n",
    "Welcome Message\n",
    "\n",
    "Chevron Down\n",
    "✔\n",
    "Welcome to Gen AI with NLP, agentic AI and Fine Tuning\n",
    "\n",
    "\n",
    "\n",
    "Resources\n",
    "✔\n",
    "8th_March_live_induction\n",
    "\n",
    "\n",
    "\n",
    "Resources\n",
    "✔\n",
    "9th_march_installation and basic data processing\n",
    "\n",
    "\n",
    "\n",
    "Resources\n",
    "✔\n",
    "15th March Embeddings\n",
    "\n",
    "\n",
    "\n",
    "Resources\n",
    "✔\n",
    "16th March Word2Vec\n",
    "\n",
    "\n",
    "\n",
    "Resources\n",
    "✔\n",
    "23rd March Neural network\n",
    "\n",
    "\n",
    "\n",
    "Resources\n",
    "✔\n",
    "29th March live RNN\n",
    "\n",
    "\n",
    "\n",
    "Resources\n",
    "8\n",
    "30th march practical NN and RNN LSTM\n",
    "\n",
    "\n",
    "\n",
    "Resources\n",
    "9\n",
    "5th April Transformers and GRU\n",
    "\n",
    "\n",
    "\n",
    "Resources\n",
    "10\n",
    "12th April various model comparision\n",
    "\n",
    "\n",
    "\n",
    "Resources\n",
    "13th April - GPT Practical from scratch\n",
    "\n",
    "\n",
    "Live Chat\n",
    "Live\n",
    "\n",
    "Resources\n",
    "\n",
    "E\n",
    "Euron\n",
    "2:34:58 pm\n",
    "r we going to train model for some of the data or a;; data?\n",
    "We will be training the model on a subset of the data to ensure efficient learning and to avoid overfitting. This approach allows us to fine-tune the model effectively.\n",
    "\n",
    "P\n",
    "Pratyush\n",
    "2:35:29 pm\n",
    "yes sir got it feeling excited\n",
    "\n",
    "S\n",
    "shashids\n",
    "2:35:44 pm\n",
    "can i use uv env here\n",
    "\n",
    "S\n",
    "Sachin\n",
    "2:35:44 pm\n",
    "Yesterday class was missed by me\n",
    "\n",
    "S\n",
    "Sachin\n",
    "2:35:48 pm\n",
    "Is there linkage\n",
    "\n",
    "S\n",
    "Sachin\n",
    "2:37:18 pm\n",
    "Ok thanks\n",
    "\n",
    "M\n",
    "Mentor sudhanshu\n",
    "2:39:05 pm\n",
    "my name is sudhanshu kumar , i work with euron , Helping Millions of Students Succeed Sudhanshu's commitment to affordable education wasn't just a business strategy—it was his life's mission. Over the years, iNeuron has helped over 1.5 million students from 34+ countries, providing them with the skills they need to succeed in today's competitive job market. Many of these students, like Sudhanshu himself, came from disadvantaged backgrounds. They saw iNeuron as a lifeline—an opportunity to rise above their circumstances.\n",
    "\n",
    "In 2022, iNeuron was acquired by PhysicsWallah in a deal worth ₹250 crore. While this acquisition was a significant milestone, Sudhanshu remained focused on his mission. Even after the acquisition, iNeuron continued to offer some of the most affordable and accessible tech courses in the world. Helping Millions of Students Succeed Sudhanshu's commitment to affordable education wasn't just a business strategy—it was his life's mission. Over the years, iNeuron has helped over 1.5 million students from 34+ countries, providing them with the skills they need to succeed in today's competitive job market. Many of these students, like Sudhanshu himself, came from disadvantaged backgrounds. They saw iNeuron as a lifeline—an opportunity to rise above their circumstances.\n",
    "\n",
    "In 2022, iNeuron was acquired by PhysicsWallah in a deal worth ₹250 crore. While this acquisition was a significant milestone, Sudhanshu remained focused on his mission. Even after the acquisition, iNeuron continued to offer some of the most affordable and accessible tech courses in the world.Sudhanshu Kumar's life is a story of triumph over adversity, driven by the belief in the transformative power of education. Born in Jamshedpur, Jharkhand, India, to a family of very modest means, Sudhanshu's early years were marked by financial hardship. His surroundings offered little opportunity, and resources were limited, yet he understood from a young age that education could be his ticket out of poverty.\n",
    "\n",
    "While many would have been daunted by the lack of support and opportunity, Sudhanshu was relentless in his pursuit of knowledge. He knew that education had the power to change lives, and he was determined to leverage it to create a better future for himself and his family. Despite the numerous challenges along the way, Sudhanshu excelled academically, eventually earning a degree in Computer Science and Engineering (CSE). After completing his education, Sudhanshu began his professional journey in the tech industry, working with prestigious companies like Wipro, Deloitte, Verizon Labs, and Ernst & Young. During this time, he gained expertise in various technologies and frameworks, including SAP WebDynpro, Fiori UI5 HANA, Java, Big Data, Data Analytics, and more. He became a well-rounded technologist, well-respected in his field.\n",
    "\n",
    "Despite his growing success, Sudhanshu never forgot his roots. He knew that there were many others who, like him, came from humble backgrounds and were looking for an opportunity to change their lives through education. It was during this time that Sudhanshu realized a harsh truth: quality education was often inaccessible to those who needed it the most. The high cost of education barred millions of people from pursuing their dreams, especially in tech fields that required specialized skills. Fueled by his passion for making education accessible, Sudhanshu decided to take action. In 2019, he founded iNeuron Intelligence Private Limited, an edtech platform that would make tech upskilling affordable and accessible for everyone. His mission was clear: to provide high-quality courses at a price so low that even those from the most disadvantaged backgrounds could afford to learn.\n",
    "\n",
    "iNeuron was designed to be more than just an online learning platform. It offered a comprehensive bundle of resources, including courses, books, hands-on projects, and live classes, making sure that learners could gain real-world, applicable skills. Most importantly, iNeuron was priced to ensure no student would be left behind due to financial constraints.\n",
    "\n",
    "The company quickly gained traction, thanks to Sudhanshu's focus on affordability and quality. In 2021, iNeuron raised $3 million in funding from S. Chand, a leading education publisher. This allowed iNeuron to expand its offerings and reach a larger audience. Building on the success of iNeuron, Sudhanshu is now leading Euron, a unified platform for tech upskilling. Euron is designed for enterprises, schools, colleges, government organizations, and individuals looking to improve their tech skills. The platform provides a comprehensive bundle of resources, including courses, books, live classes, and projects. Euron's unique offering is its ability to provide licenses at scale—organizations can subscribe to provide their teams with unlimited access to learning materials for just 1600 INR per year per license.\n",
    "\n",
    "For individuals, Euron Plus offers a similar plan, priced at 2900 INR per year, giving learners access to all of Euron's content, along with 24/7 support through Euron Assist. The idea is simple: anyone, anywhere, should have the opportunity to upskill without financial barriers.\n",
    "\n",
    "The Euron Motto: Education for All, Without Limits\n",
    "\n",
    "At the heart of Euron's philosophy is a single, powerful idea: Education for All, Without Limits. Sudhanshu believes that every person deserves the chance to learn, grow, and succeed, regardless of their financial situation or background. This belief is what drives Euron's mission to make tech education not just affordable but also accessible to anyone, anywhere in the world.\n",
    "\n",
    "D\n",
    "Deepak\n",
    "2:40:08 pm\n",
    "done sir\n",
    "\n",
    "D\n",
    "Durgesh\n",
    "2:40:09 pm\n",
    "yes\n",
    "\n",
    "R\n",
    "Rathlavath\n",
    "2:40:15 pm\n",
    "Hi Sir, I’m currently working as an AI Engineer where I fine-tune LLMs and VLMs. I’ve already covered basics like preprocessing and tokenization in previous courses. Since this is my first class with you, just wanted to check—will I be able to follow along with the content?\n",
    "\n",
    "J\n",
    "Joe\n",
    "2:40:17 pm\n",
    "yes\n",
    "\n",
    "D\n",
    "Dr\n",
    "2:40:36 pm\n",
    "No\n",
    "\n",
    "R\n",
    "Rathlavath\n",
    "2:41:00 pm\n",
    "Hi Sir, I’m currently working as an AI Engineer where I fine-tune LLMs and VLMs. I’ve already covered basics like preprocessing and tokenization in previous courses. Since this is my first class with you, just wanted to check—will I be able to follow along with the content?\n",
    "\n",
    "E\n",
    "Euron\n",
    "2:41:17 pm\n",
    "Hi Sir, I’m currently working as an AI Engineer where I fine-tune LLMs and VLMs. I’ve already covered basics like preprocessing and tokenization in previous courses. Since this is my first class with you, just wanted to check—will I be able to follow along with the content?\n",
    "Absolutely! Since you have experience with fine-tuning LLMs and VLMs, along with a solid understanding of preprocessing and tokenization, you should be well-equipped to follow along with the content in this course. The lecture will build on those fundamentals, so you'll find it engaging and informative. Welcome aboard!\n",
    "\n",
    "R\n",
    "Rathlavath\n",
    "2:41:42 pm\n",
    "Okay Sir Thank you.\n",
    "\n",
    "R\n",
    "Rathlavath\n",
    "2:41:48 pm\n",
    "by the way my name is Rathlavath Ramesh\n",
    "\n",
    "E\n",
    "Euron\n",
    "2:42:06 pm\n",
    "Hi Sir, I’m currently working as an AI Engineer where I fine-tune LLMs and VLMs. I’ve already covered basics like preprocessing and tokenization in previous courses. Since this is my first class with you, just wanted to check—will I be able to follow along with the content?\n",
    "Absolutely! Since you have experience with fine-tuning LLMs and VLMs, along with a solid understanding of preprocessing and tokenization, you should be well-equipped to follow along with the content in this course. The lecture will build on those concepts, so you'll find it engaging and informative. Welcome aboard!\n",
    "\n",
    "R\n",
    "Roja\n",
    "2:42:48 pm\n",
    "decoder only\n",
    "\n",
    "S\n",
    "Sundar\n",
    "2:42:48 pm\n",
    "decoder only\n",
    "\n",
    "R\n",
    "Rajat\n",
    "2:42:50 pm\n",
    "Decoder only\n",
    "\n",
    "D\n",
    "Durgesh\n",
    "2:42:51 pm\n",
    "decoder\n",
    "\n",
    "S\n",
    "Sachin\n",
    "2:42:52 pm\n",
    "decoder\n",
    "\n",
    "M\n",
    "Manas\n",
    "2:42:52 pm\n",
    "Decoder\n",
    "\n",
    "S\n",
    "Sai\n",
    "2:42:53 pm\n",
    "decoder only\n",
    "\n",
    "R\n",
    "Ram\n",
    "2:42:54 pm\n",
    "decoder\n",
    "\n",
    "R\n",
    "Rathlavath\n",
    "2:42:54 pm\n",
    "encoder and decoded\n",
    "\n",
    "A\n",
    "ANKIT\n",
    "2:42:55 pm\n",
    "decoder only\n",
    "\n",
    "D\n",
    "Debkumar\n",
    "2:42:58 pm\n",
    "Decoder only\n",
    "\n",
    "D\n",
    "Deepak\n",
    "2:42:59 pm\n",
    "Decoder\n",
    "\n",
    "A\n",
    "Ashish\n",
    "2:43:03 pm\n",
    "decoder\n",
    "\n",
    "S\n",
    "shashids\n",
    "2:43:06 pm\n",
    "decoder\n",
    "\n",
    "J\n",
    "Joe\n",
    "2:43:08 pm\n",
    "Decoder\n",
    "\n",
    "D\n",
    "Dr\n",
    "2:43:08 pm\n",
    "decoder\n",
    "\n",
    "A\n",
    "Anand\n",
    "2:43:09 pm\n",
    "Decoder only\n",
    "\n",
    "R\n",
    "Rathlavath\n",
    "2:43:10 pm\n",
    "both encoder and decoder model\n",
    "\n",
    "S\n",
    "Santosh\n",
    "2:43:13 pm\n",
    "decoder\n",
    "\n",
    "S\n",
    "subhadip\n",
    "2:43:40 pm\n",
    "Decoder only5\n",
    "\n",
    "R\n",
    "Rathlavath\n",
    "2:43:43 pm\n",
    "yeah initial only decoder sir\n",
    "\n",
    "R\n",
    "Rathlavath\n",
    "2:43:52 pm\n",
    "latest one is both of them\n",
    "\n",
    "E\n",
    "Euron\n",
    "2:44:12 pm\n",
    "both encoder and decoder model\n",
    "An encoder-decoder model is a type of neural network architecture commonly used in tasks like machine translation. The encoder processes the input data and compresses it into a context vector, while the decoder takes this context and generates the output sequence. In the context of GPT, which primarily uses a decoder-only architecture, the focus is on generating text based on the input prompt rather than translating or transforming sequences.\n",
    "\n",
    "T\n",
    "teja\n",
    "2:44:30 pm\n",
    "decodrer model\n",
    "\n",
    "T\n",
    "teja\n",
    "2:44:44 pm\n",
    "gpt decoder\n",
    "\n",
    "M\n",
    "Mentor sudhanshu\n",
    "2:46:58 pm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "Copy\n",
    "M\n",
    "Mentor sudhanshu\n",
    "2:48:22 pm\n",
    "with open(\"data.txt\",'r',encoding='utf-8') as f :\n",
    "    text_data  = f.read()\n",
    "Copy\n",
    "P\n",
    "Purna\n",
    "2:49:43 pm\n",
    "can you please share the data.txt again\n",
    "\n",
    "D\n",
    "Durgesh\n",
    "2:50:06 pm\n",
    "yes\n",
    "\n",
    "D\n",
    "Deepak\n",
    "2:50:07 pm\n",
    "Yes sir\n",
    "\n",
    "D\n",
    "Debkumar\n",
    "2:50:13 pm\n",
    "yes\n",
    "\n",
    "V\n",
    "VIJAY\n",
    "2:50:15 pm\n",
    "yes\n",
    "\n",
    "J\n",
    "Jitendra\n",
    "2:50:15 pm\n",
    "yeap\n",
    "\n",
    "A\n",
    "Ashish\n",
    "2:50:17 pm\n",
    "yes\n",
    "\n",
    "J\n",
    "Joe\n",
    "2:50:18 pm\n",
    "yes\n",
    "\n",
    "S\n",
    "Sachin\n",
    "2:50:20 pm\n",
    "yes\n",
    "\n",
    "A\n",
    "Aman\n",
    "2:50:21 pm\n",
    "If my data is in multiple pdf/word files then ?\n",
    "\n",
    "E\n",
    "Euron\n",
    "2:51:24 pm\n",
    "If my data is in multiple pdf/word files then ?\n",
    "You can use tools like Python's PyPDF2 or docx libraries to extract text from PDF and Word files. Once you have the data in a structured format, you can process it for your NLP tasks. If you're looking to fine-tune a model, consider converting the text into a suitable format like JSON or CSV for easier handling.\n",
    "\n",
    "M\n",
    "Mentor sudhanshu\n",
    "2:54:16 pm\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=5000,oov_token='<OOV>') tokenizer.fit_on_texts([text_data])\n",
    "\n",
    "M\n",
    "Mentor sudhanshu\n",
    "2:54:22 pm\n",
    "sequence = tokenizer.texts_to_sequences([text_data])\n",
    "Copy\n",
    "M\n",
    "Mentor sudhanshu\n",
    "2:55:23 pm\n",
    "sequence = tokenizer.texts_to_sequences([text_data])[0]\n",
    "Copy\n",
    "M\n",
    "Mentor sudhanshu\n",
    "2:58:02 pm\n",
    "with open(\"tokenizer.pkl\",'wb')  as f :\n",
    "    pickle.dump(tokenizer,f)\n",
    "Copy\n",
    "D\n",
    "Durgesh\n",
    "2:58:25 pm\n",
    "yes\n",
    "\n",
    "D\n",
    "Deepak\n",
    "2:58:30 pm\n",
    "Yes sir\n",
    "\n",
    "A\n",
    "Ashish\n",
    "2:58:35 pm\n",
    "yes\n",
    "\n",
    "D\n",
    "Dr\n",
    "2:58:36 pm\n",
    "sir please repeat pickle\n",
    "\n",
    "V\n",
    "VIJAY\n",
    "2:58:56 pm\n",
    "yes\n",
    "\n",
    "S\n",
    "Sachin\n",
    "2:58:56 pm\n",
    "yes'\n",
    "\n",
    "J\n",
    "Jitendra\n",
    "2:58:57 pm\n",
    "yeap\n",
    "\n",
    "J\n",
    "Joe\n",
    "2:58:58 pm\n",
    "yes\n",
    "\n",
    "G\n",
    "Ganesh\n",
    "2:59:00 pm\n",
    "yes sir\n",
    "\n",
    "S\n",
    "Santosh\n",
    "2:59:07 pm\n",
    "Yes\n",
    "\n",
    "A\n",
    "Abhishek\n",
    "2:59:14 pm\n",
    "yes\n",
    "\n",
    "D\n",
    "Debanjan\n",
    "2:59:15 pm\n",
    "tried import tokenizer it's throwing no module named tensorflow\n",
    "\n",
    "C\n",
    "Chetan\n",
    "2:59:25 pm\n",
    "yes\n",
    "\n",
    "D\n",
    "Deepak\n",
    "2:59:35 pm\n",
    "Sir when I print sequences, it's showing me none sir\n",
    "\n",
    "D\n",
    "Dr\n",
    "2:59:40 pm\n",
    "ok .thnaks\n",
    "\n",
    "D\n",
    "Dr\n",
    "2:59:43 pm\n",
    "thanks\n",
    "\n",
    "D\n",
    "Debanjan\n",
    "2:59:57 pm\n",
    "ok\n",
    "\n",
    "S\n",
    "Santosh\n",
    "3:00:11 pm\n",
    "some people use joblib as well\n",
    "\n",
    "E\n",
    "Euron\n",
    "3:00:18 pm\n",
    "tried import tokenizer it's throwing no module named tensorflow\n",
    "It seems like you're trying to use TensorFlow but it's not installed in your environment. You can install it using pip with the command pip install tensorflow. Make sure to check your Python environment and ensure that you're using the correct one where TensorFlow is installed.\n",
    "\n",
    "E\n",
    "Euron\n",
    "3:00:40 pm\n",
    "Sir when I print sequences, it's showing me none sir\n",
    "It sounds like your print statement might be returning None because the function you're calling doesn't have a return value. Make sure that the function is returning the sequence you want to print. If you're using a loop, ensure you're printing the values inside the loop correctly. If you need more specific help, feel free to share your code!\n",
    "\n",
    "U\n",
    "Utkarsh\n",
    "3:00:54 pm\n",
    "why do we need to store in binary format\n",
    "\n",
    "D\n",
    "Deepak\n",
    "3:00:55 pm\n",
    "Sir when I print sequences, it's showing me none sir\n",
    "\n",
    "D\n",
    "Deepak\n",
    "3:01:02 pm\n",
    "Sir when I print sequences, it's showing me none sir\n",
    "\n",
    "S\n",
    "satish\n",
    "3:01:43 pm\n",
    "yes\n",
    "\n",
    "J\n",
    "Joe\n",
    "3:01:46 pm\n",
    "yes\n",
    "\n",
    "E\n",
    "Euron\n",
    "3:01:57 pm\n",
    "Sir when I print sequences, it's showing me none sir\n",
    "It sounds like your print statement might be returning None because the function you're calling doesn't have a return value. Make sure that the function you're using to generate the sequences is returning the expected output. If you're using a loop, ensure you're printing the sequences correctly within the loop. If you need more specific help, feel free to share your code!\n",
    "\n",
    "E\n",
    "Euron\n",
    "3:01:58 pm\n",
    "why do we need to store in binary format\n",
    "Storing data in binary format is essential because it allows for efficient storage and processing. Binary representation uses less space and enables faster computation, as computers operate on binary data. This is particularly important in AI and NLP, where large datasets are common.\n",
    "\n",
    "E\n",
    "Euron\n",
    "3:02:05 pm\n",
    "Sir when I print sequences, it's showing me none sir\n",
    "It sounds like your print statement might be returning None because the function you're calling doesn't have a return value. Make sure that the function you're using to generate the sequences is returning the expected output. If you're using a loop, ensure you're printing the sequences correctly within the loop. If you need more specific help, feel free to share your code!\n",
    "\n",
    "R\n",
    "Roja\n",
    "3:02:48 pm\n",
    "yes\n",
    "\n",
    "D\n",
    "Durgesh\n",
    "3:02:51 pm\n",
    "yes\n",
    "\n",
    "D\n",
    "Deepak\n",
    "3:02:52 pm\n",
    "Yes\n",
    "\n",
    "G\n",
    "Ganesh\n",
    "3:02:52 pm\n",
    "yes\n",
    "\n",
    "P\n",
    "Pratyush\n",
    "3:02:52 pm\n",
    "yes\n",
    "\n",
    "S\n",
    "Sachin\n",
    "3:02:53 pm\n",
    "yes\n",
    "\n",
    "D\n",
    "Dr\n",
    "3:02:56 pm\n",
    "yes\n",
    "\n",
    "A\n",
    "Ashish\n",
    "3:02:58 pm\n",
    "yes\n",
    "\n",
    "D\n",
    "Devansh\n",
    "3:03:12 pm\n",
    "can anyone share entire code until now\n",
    "\n",
    "S\n",
    "satish\n",
    "3:03:32 pm\n",
    "x and y are same\n",
    "\n",
    "S\n",
    "Santosh\n",
    "3:03:48 pm\n",
    "x=text, y= encoding token\n",
    "\n",
    "S\n",
    "Sai\n",
    "3:03:53 pm\n",
    "current word --> next word\n",
    "\n",
    "S\n",
    "Sundar\n",
    "3:04:07 pm\n",
    "subsequent token will be y for the input sequence selected iteratively\n",
    "\n",
    "D\n",
    "Deepak\n",
    "3:04:15 pm\n",
    "sir, I think we need to add tokenizer.fit_on_texts() before calling texts_to_sequences....is it correct sir ?\n",
    "\n",
    "D\n",
    "Dishank\n",
    "3:04:27 pm\n",
    "X is test\n",
    "\n",
    "R\n",
    "Rajat\n",
    "3:04:29 pm\n",
    "x = current_word y = next word\n",
    "\n",
    "D\n",
    "Dr\n",
    "3:04:38 pm\n",
    "30 : 70 test and train of same data\n",
    "\n",
    "S\n",
    "Sachin\n",
    "3:04:41 pm\n",
    "input will be before word and output will be next work\n",
    "\n",
    "S\n",
    "Sameer\n",
    "3:04:42 pm\n",
    "x=input, y=expected output\n",
    "\n",
    "S\n",
    "Sandeep\n",
    "3:05:04 pm\n",
    "we mask our data\n",
    "\n",
    "E\n",
    "Euron\n",
    "3:05:09 pm\n",
    "subsequent token will be y for the input sequence selected iteratively\n",
    "In the context of generative models like GPT, a subsequent token refers to the next word or symbol predicted based on the input sequence. When generating text, the model iteratively selects the next token (y) using probabilities derived from the preceding tokens. This process continues until a stopping criterion is met, such as reaching a maximum length or generating a specific end token.\n",
    "\n",
    "E\n",
    "Euron\n",
    "3:05:16 pm\n",
    "sir, I think we need to add tokenizer.fit_on_texts() before calling texts_to_sequences....is it correct sir ?\n",
    "Yes, you're correct! You need to call tokenizer.fit_on_texts() before using texts_to_sequences(). This step ensures that the tokenizer learns the vocabulary from your texts, allowing it to convert them into sequences properly.\n",
    "\n",
    "M\n",
    "Manas\n",
    "3:05:26 pm\n",
    "X is input/s and Y is output\n",
    "\n",
    "E\n",
    "Euron\n",
    "3:05:41 pm\n",
    "30 : 70 test and train of same data\n",
    "When you split data into training and testing sets, a common ratio is 70:30. This means 70% of your data is used to train the model, while 30% is reserved for testing its performance. However, using the same data for both training and testing can lead to overfitting, where the model performs well on the training data but poorly on unseen data. It's crucial to have separate datasets to evaluate the model's generalization ability effectively.\n",
    "\n",
    "D\n",
    "Deepak\n",
    "3:05:56 pm\n",
    "sir , do we need to add tokenizer.fit_on_texts() before calling texts_to_sequences.\n",
    "\n",
    "E\n",
    "Euron\n",
    "3:06:58 pm\n",
    "sir , do we need to add tokenizer.fit_on_texts() before calling texts_to_sequences.\n",
    "Yes, you need to call tokenizer.fit_on_texts() before using texts_to_sequences(). This step builds the vocabulary based on your texts, allowing the tokenizer to convert the words into their corresponding integer sequences.\n",
    "\n",
    "D\n",
    "Dr\n",
    "3:09:23 pm\n",
    "i am not able to understand .please explain\n",
    "\n",
    "J\n",
    "Joe\n",
    "3:09:54 pm\n",
    "yes\n",
    "\n",
    "D\n",
    "Dr\n",
    "3:10:03 pm\n",
    "ok\n",
    "\n",
    "D\n",
    "Dr\n",
    "3:10:21 pm\n",
    "got it\n",
    "\n",
    "U\n",
    "Utkarsh\n",
    "3:10:40 pm\n",
    "any reason for choosing window size at 32\n",
    "\n",
    "D\n",
    "Durgesh\n",
    "3:11:36 pm\n",
    "yes\n",
    "\n",
    "J\n",
    "Joe\n",
    "3:11:37 pm\n",
    "clear\n",
    "\n",
    "E\n",
    "Euron\n",
    "3:11:42 pm\n",
    "any reason for choosing window size at 32\n",
    "The choice of a window size of 32 often balances the need for context and computational efficiency. It allows the model to capture enough surrounding information without overwhelming it with too much data, which can lead to noise and reduced performance. This size is commonly used in NLP tasks to optimize training and inference times.\n",
    "\n",
    "D\n",
    "Deepak\n",
    "3:11:43 pm\n",
    "Now I am getting it sir\n",
    "\n",
    "D\n",
    "Dr\n",
    "3:11:43 pm\n",
    "clear\n",
    "\n",
    "S\n",
    "Sundar\n",
    "3:11:45 pm\n",
    "sir, can you please let me know if the tokenization did was at word level or character level?\n",
    "\n",
    "J\n",
    "Joe\n",
    "3:12:03 pm\n",
    "yes\n",
    "\n",
    "E\n",
    "Euron\n",
    "3:12:49 pm\n",
    "sir, can you please let me know if the tokenization did was at word level or character level?\n",
    "Tokenization can be done at both word level and character level, depending on the specific requirements of the model and the task. In the context of GPT, it typically uses subword tokenization, which is a hybrid approach that breaks down words into smaller units, allowing for better handling of rare words and improving efficiency.\n",
    "\n",
    "D\n",
    "Deepak\n",
    "3:13:49 pm\n",
    "Yes sir\n",
    "\n",
    "R\n",
    "Roja\n",
    "3:13:50 pm\n",
    "yes\n",
    "\n",
    "D\n",
    "Dr\n",
    "3:14:07 pm\n",
    "ekdam clear\n",
    "\n",
    "D\n",
    "Durgesh\n",
    "3:14:07 pm\n",
    "yes\n",
    "\n",
    "D\n",
    "Deepak\n",
    "3:14:11 pm\n",
    "Getting it sir\n",
    "\n",
    "J\n",
    "Joe\n",
    "3:14:11 pm\n",
    "yes\n",
    "\n",
    "S\n",
    "shashids\n",
    "3:14:13 pm\n",
    "YES\n",
    "\n",
    "T\n",
    "teja\n",
    "3:14:20 pm\n",
    "window_size can you justify in this example\n",
    "\n",
    "S\n",
    "Santosh\n",
    "3:14:30 pm\n",
    "yes\n",
    "\n",
    "P\n",
    "Pratyush\n",
    "3:15:04 pm\n",
    "yes\n",
    "\n",
    "D\n",
    "Debanjan\n",
    "3:15:12 pm\n",
    "sir tensorflow.keras import layers throwing DLL exception\n",
    "\n",
    "D\n",
    "Deepak\n",
    "3:15:39 pm\n",
    "Completely getting sir\n",
    "\n",
    "D\n",
    "Debanjan\n",
    "3:15:39 pm\n",
    "confused what to do\n",
    "\n",
    "M\n",
    "Manas\n",
    "3:15:41 pm\n",
    "yes\n",
    "\n",
    "A\n",
    "Ashish\n",
    "3:15:46 pm\n",
    "yes\n",
    "\n",
    "D\n",
    "Dr\n",
    "3:15:47 pm\n",
    "yes\n",
    "\n",
    "J\n",
    "Joe\n",
    "3:16:00 pm\n",
    "correct\n",
    "\n",
    "S\n",
    "Santosh\n",
    "3:16:02 pm\n",
    "array dimension is 32 becuae of WS\n",
    "\n",
    "E\n",
    "Euron\n",
    "3:16:16 pm\n",
    "sir tensorflow.keras import layers throwing DLL exception\n",
    "It sounds like you're encountering a DLL exception when trying to import layers from TensorFlow Keras. This issue can often be related to a few common factors:\n",
    "\n",
    "Environment Issues: Ensure that your Python environment is set up correctly. Sometimes, conflicts with other packages can cause DLL issues.\n",
    "\n",
    "TensorFlow Installation: Make sure you have the correct version of TensorFlow installed. You can try reinstalling it using pip:\n",
    "\n",
    "pip uninstall tensorflow\n",
    "   pip install tensorflow\n",
    "Copy\n",
    "Dependencies: Check if all required dependencies are installed. You might need to install or update packages like NumPy or others that TensorFlow relies on.\n",
    "\n",
    "System Compatibility: Ensure that your system meets the requirements for TensorFlow, especially if you're using a GPU version.\n",
    "\n",
    "If the problem persists, consider checking the TensorFlow GitHub issues page for similar reports or solutions.\n",
    "\n",
    "D\n",
    "Deepak\n",
    "3:16:58 pm\n",
    "Why starting from 158 sir\n",
    "\n",
    "S\n",
    "Santosh\n",
    "3:17:16 pm\n",
    "got 100% now\n",
    "\n",
    "T\n",
    "teja\n",
    "3:17:19 pm\n",
    "yes\n",
    "\n",
    "D\n",
    "Durgesh\n",
    "3:18:05 pm\n",
    "positional encoding\n",
    "\n",
    "S\n",
    "Sai\n",
    "3:18:05 pm\n",
    "input embedding\n",
    "\n",
    "D\n",
    "Dr\n",
    "3:18:16 pm\n",
    "embedgin\n",
    "\n",
    "D\n",
    "Debanjan\n",
    "3:18:17 pm\n",
    "sir, tensorflow.keras import layers throwing DLL exception, confused with that\n",
    "\n",
    "S\n",
    "satish\n",
    "3:18:19 pm\n",
    "positional encoding\n",
    "\n",
    "P\n",
    "Papa\n",
    "3:18:21 pm\n",
    "Pe\n",
    "\n",
    "S\n",
    "Santosh\n",
    "3:18:23 pm\n",
    "positinal enc\n",
    "\n",
    "D\n",
    "Dr\n",
    "3:18:41 pm\n",
    "positional encoding\n",
    "\n",
    "R\n",
    "Roja\n",
    "3:18:53 pm\n",
    "what is the input embedding size here ?is it window size that we took?\n",
    "\n",
    "D\n",
    "Devansh\n",
    "3:19:04 pm\n",
    "bpe\n",
    "\n",
    "E\n",
    "Euron\n",
    "3:19:07 pm\n",
    "positional encoding\n",
    "Positional encoding is a technique used in transformer models to give the model information about the position of words in a sequence. Since transformers process all words simultaneously, they need a way to understand the order of words. Positional encodings are added to the input embeddings to provide this context, typically using sine and cosine functions to create unique encodings for each position. This allows the model to capture the sequential nature of language effectively.\n",
    "\n",
    "S\n",
    "Sai\n",
    "3:19:10 pm\n",
    "bpe\n",
    "\n",
    "D\n",
    "Dr\n",
    "3:19:11 pm\n",
    "rotational\n",
    "\n",
    "S\n",
    "Sachin\n",
    "3:19:11 pm\n",
    "sinisodial\n",
    "\n",
    "R\n",
    "Rajat\n",
    "3:19:21 pm\n",
    "RoPE\n",
    "\n",
    "E\n",
    "Euron\n",
    "3:19:22 pm\n",
    "sir, tensorflow.keras import layers throwing DLL exception, confused with that\n",
    "It sounds like you're encountering a DLL exception when trying to import layers from TensorFlow Keras. This issue can often be related to a few common factors:\n",
    "\n",
    "Environment Issues: Ensure that your Python environment is set up correctly. Sometimes, conflicts with other packages can cause DLL issues.\n",
    "\n",
    "TensorFlow Installation: Make sure you have the correct version of TensorFlow installed. You can reinstall it using pip:\n",
    "\n",
    "pip uninstall tensorflow\n",
    "   pip install tensorflow\n",
    "Copy\n",
    "Dependencies: Check if all required dependencies are installed. You might need to install or update packages like NumPy or others that TensorFlow relies on.\n",
    "\n",
    "System Compatibility: Ensure that your system meets the requirements for the version of TensorFlow you are using, especially if you're on Windows.\n",
    "\n",
    "If the problem persists, consider checking the TensorFlow GitHub issues page for similar reports or solutions.\n",
    "\n",
    "E\n",
    "Euron\n",
    "3:19:24 pm\n",
    "positional encoding\n",
    "Positional encoding is a technique used in transformer models to give the model information about the position of words in a sequence. Since transformers process all words simultaneously, they need a way to understand the order of words. Positional encodings are added to the input embeddings to provide this context, allowing the model to capture the sequential nature of language.\n",
    "\n",
    "K\n",
    "kumar\n",
    "3:19:25 pm\n",
    "rotatory\n",
    "\n",
    "R\n",
    "Roja\n",
    "3:19:34 pm\n",
    "what is the input embedding size here ?is it window size that we took?\n",
    "\n",
    "E\n",
    "Euron\n",
    "3:19:43 pm\n",
    "positional encoding\n",
    "Positional encoding is a technique used in transformer models to give the model information about the position of words in a sequence. Since transformers process input data in parallel, they lack a built-in sense of order. Positional encodings are added to the input embeddings to help the model understand the sequence of words, allowing it to capture the relationships between them effectively.\n",
    "\n",
    "E\n",
    "Euron\n",
    "3:19:56 pm\n",
    "what is the input embedding size here ?is it window size that we took?\n",
    "The input embedding size typically refers to the dimensionality of the vector representation for each token in your input data, not the window size. The window size usually pertains to the context length or the number of tokens considered at once during processing. In the context of GPT, the embedding size is often defined by the model architecture itself.\n",
    "\n",
    "E\n",
    "Euron\n",
    "3:20:36 pm\n",
    "what is the input embedding size here ?is it window size that we took?\n",
    "The input embedding size typically refers to the dimensionality of the vectors used to represent input tokens, not the window size. The window size usually pertains to the context length or the number of tokens considered at once during processing. In the context of GPT, the embedding size is often fixed and defined by the model architecture.\n",
    "\n",
    "S\n",
    "Santosh\n",
    "3:22:28 pm\n",
    "sir copy paste then\n",
    "\n",
    "S\n",
    "Sai\n",
    "3:24:21 pm\n",
    "512\n",
    "\n",
    "D\n",
    "Devansh\n",
    "3:24:26 pm\n",
    "dimension\n",
    "\n",
    "R\n",
    "Roja\n",
    "3:24:27 pm\n",
    "embedding size\n",
    "\n",
    "K\n",
    "kumar\n",
    "3:24:32 pm\n",
    "512\n",
    "\n",
    "S\n",
    "Sameer\n",
    "3:24:33 pm\n",
    "32\n",
    "\n",
    "D\n",
    "Dr\n",
    "3:24:38 pm\n",
    "512\n",
    "\n",
    "D\n",
    "Debkumar\n",
    "3:25:04 pm\n",
    "dimension=512\n",
    "\n",
    "R\n",
    "Rajat\n",
    "3:25:06 pm\n",
    "100 for the code, 512 for transformer\n",
    "\n",
    "R\n",
    "Roja\n",
    "3:28:00 pm\n",
    "sir ,usually each token will be converted into fixed size of embedding size. why it is not done here? .here we are taking as max_input_length as the input\n",
    "\n",
    "E\n",
    "Euron\n",
    "3:29:03 pm\n",
    "sir ,usually each token will be converted into fixed size of embedding size. why it is not done here? .here we are taking as max_input_length as the input\n",
    "In this context, the max_input_length is used to define the maximum number of tokens the model can process at once. Instead of converting each token into a fixed-size embedding, the model may utilize dynamic embeddings based on the input length, allowing for more flexibility and efficiency in handling varying input sizes. This approach can help capture more context and nuances in the data.\n",
    "\n",
    "M\n",
    "Mentor sudhanshu\n",
    "3:29:34 pm\n",
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self,max_len,d_model):\n",
    "        super().__init__()\n",
    "        pos = np.arange(max_len)[:,np.newaxis]\n",
    "        i = np.arange(d_model)[np.newaxis,:]\n",
    "        angle_rates = 1/np.power(10000,(2*(i//2))/np.float32(d_model))\n",
    "        angle_rads = pos.angle_rates\n",
    "        angle_rads[:,0::2] = np.sin(angle_rads[:,0::2])\n",
    "        angle_rads[:,1::2] = np.cos(angle_rads[:,1::2])\n",
    "        self.pos_encoding = tf.cast(angle_rads[np.newaxis,...],dtype=tf.float32)\n",
    "        \n",
    "    def call(self,x):\n",
    "        return x+self.pos_encoding[:,:tf.shape(x)[1],:]\n",
    "Copy\n",
    "R\n",
    "Roja\n",
    "3:30:02 pm\n",
    "embedding size of the input\n",
    "\n",
    "E\n",
    "Euron\n",
    "3:31:04 pm\n",
    "embedding size of the input\n",
    "The embedding size of the input typically depends on the model architecture you're using. For models like GPT, common sizes range from 256 to 2048 dimensions. It's important to choose an embedding size that balances performance and computational efficiency based on your specific task.\n",
    "\n",
    "A\n",
    "Aman\n",
    "3:33:11 pm\n",
    "what is dropout = 0.1 ?\n",
    "\n",
    "A\n",
    "ANKIT\n",
    "3:33:49 pm\n",
    "100\n",
    "\n",
    "S\n",
    "Santosh\n",
    "3:33:57 pm\n",
    "100\n",
    "\n",
    "E\n",
    "Euron\n",
    "3:34:13 pm\n",
    "what is dropout = 0.1 ?\n",
    "Dropout = 0.1 refers to a regularization technique used in neural networks to prevent overfitting. It means that during training, 10% of the neurons are randomly \"dropped out\" or ignored in each iteration. This helps the model generalize better to unseen data.\n",
    "\n",
    "D\n",
    "Dr\n",
    "3:38:26 pm\n",
    "masking?\n",
    "\n",
    "M\n",
    "Mentor sudhanshu\n",
    "3:39:29 pm\n",
    "def transformer_block(embed_dim , num_heads,ff_dim,dropout = .1):\n",
    "    input = layers.Input(shape=(None,embed_dim))\n",
    "    attn_output = layers.MultiHeadAttention(num_heads = num_heads ,key_dim = embed_dim)(input,input)\n",
    "    attn_output = layers.Droupout(dropout)(attn_output)\n",
    "    out1 = layers.LayerNormalization(epsilon = 1e-6)(input + attn_output)\n",
    "Copy\n",
    "J\n",
    "Joe\n",
    "3:40:05 pm\n",
    "yes\n",
    "\n",
    "S\n",
    "Santosh\n",
    "3:40:10 pm\n",
    "yes\n",
    "\n",
    "K\n",
    "kumar\n",
    "3:40:42 pm\n",
    "(input,input) explain\n",
    "\n",
    "D\n",
    "Durgesh\n",
    "3:40:55 pm\n",
    "yes\n",
    "\n",
    "S\n",
    "Santosh\n",
    "3:43:36 pm\n",
    "there is typo in first dropout line of code\n",
    "\n",
    "E\n",
    "Euron\n",
    "3:44:38 pm\n",
    "there is typo in first dropout line of code\n",
    "Thanks for pointing that out! Please share the specific line of code, and I can help you correct the typo.\n",
    "\n",
    "R\n",
    "Rajat\n",
    "3:45:34 pm\n",
    "isn'e that same as encoder\n",
    "\n",
    "J\n",
    "Joe\n",
    "3:45:59 pm\n",
    "yes\n",
    "\n",
    "S\n",
    "Santosh\n",
    "3:46:11 pm\n",
    "y\n",
    "\n",
    "D\n",
    "Dr\n",
    "3:46:26 pm\n",
    "yes.\n",
    "\n",
    "A\n",
    "Aman\n",
    "3:46:55 pm\n",
    "why only feed forward is in argument ?\n",
    "\n",
    "R\n",
    "Rajat\n",
    "3:47:14 pm\n",
    "yes\n",
    "\n",
    "D\n",
    "Dr\n",
    "3:47:29 pm\n",
    "yes\n",
    "\n",
    "E\n",
    "Euron\n",
    "3:47:57 pm\n",
    "why only feed forward is in argument ?\n",
    "In the context of GPT and similar models, \"feed forward\" refers to the architecture where data moves in one direction—from input to output—without looping back. This design simplifies processing and allows for efficient training. Other architectures, like recurrent networks, involve feedback loops, but feed forward networks are often preferred for tasks like text generation due to their speed and scalability.\n",
    "\n",
    "M\n",
    "Mentor sudhanshu\n",
    "3:48:58 pm\n",
    "def transformer_block(embed_dim , num_heads,ff_dim,dropout = .1):\n",
    "    input = layers.Input(shape=(None,embed_dim))\n",
    "    attn_output = layers.MultiHeadAttention(num_heads = num_heads ,key_dim = embed_dim)(input,input)\n",
    "    attn_output = layers.Droupout(dropout)(attn_output)\n",
    "    out1 = layers.LayerNormalization(epsilon = 1e-6)(input + attn_output)\n",
    "    \n",
    "    \n",
    "    ffn = tf.keras.Sequential([\n",
    "        layers.Dense(ff_dim,activation = 'relu'),\n",
    "        layers.Dense(embed_dim)\n",
    "    ])\n",
    "    \n",
    "    ffn_output = ffn(out1)\n",
    "    ffn_output = layers.Dropout(dropout)(ffn_output)\n",
    "    out2 = layers.LayerNormalization(epsilon = 1e-6)(out1+ffn_output)\n",
    "    return tf.keras.Model(input=input,outputs = out2)\n",
    "Copy\n",
    "M\n",
    "Mentor sudhanshu\n",
    "3:56:18 pm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b774e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
