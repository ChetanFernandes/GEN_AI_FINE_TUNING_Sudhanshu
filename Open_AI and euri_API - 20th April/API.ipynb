{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a35cf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in g:\\gen ai\\venv\\lib\\site-packages (1.76.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in g:\\gen ai\\venv\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in g:\\gen ai\\venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in g:\\gen ai\\venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in g:\\gen ai\\venv\\lib\\site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in g:\\gen ai\\venv\\lib\\site-packages (from openai) (2.11.3)\n",
      "Requirement already satisfied: sniffio in g:\\gen ai\\venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in g:\\gen ai\\venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in g:\\gen ai\\venv\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in g:\\gen ai\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in g:\\gen ai\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in g:\\gen ai\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in g:\\gen ai\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in g:\\gen ai\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in g:\\gen ai\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in g:\\gen ai\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Requirement already satisfied: colorama in g:\\gen ai\\venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8668cb5",
   "metadata": {},
   "source": [
    "# Calling API with OPEAN AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10201cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b21e6f3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m openai.api_key = \u001b[33m\"\u001b[39m\u001b[33msk-proj-5kJz9vyZMrV9TVxCoLIh4dIVxh4GTIuu5EGC3jdGF56e-yehJeKGnxtsWXIGpahXK6oqFPEmPIT3BlbkFJ-VmtQ6kruS8VyLDAj2eeGMAWiECNka7uKYVPzPmFWohozZxUGx7c4DoNTkDrx5eFUPx1df3oQA\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-3.5-turbo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43mprompt\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWrite a poem about the beauty of nature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Controls randomness: 0.0 is deterministic, 1.0 is very random  \u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\GEN AI\\venv\\Lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[39m, in \u001b[36mChatCompletion.create\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     27\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time.time() > start + timeout:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\GEN AI\\venv\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[39m, in \u001b[36mEngineAPIResource.create\u001b[39m\u001b[34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    129\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    136\u001b[39m     **params,\n\u001b[32m    137\u001b[39m ):\n\u001b[32m    138\u001b[39m     (\n\u001b[32m    139\u001b[39m         deployment_id,\n\u001b[32m    140\u001b[39m         engine,\n\u001b[32m   (...)\u001b[39m\u001b[32m    150\u001b[39m         api_key, api_base, api_type, api_version, organization, **params\n\u001b[32m    151\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     response, _, api_key = \u001b[43mrequestor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[32m    164\u001b[39m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[32m    165\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\GEN AI\\venv\\Lib\\site-packages\\openai\\api_requestor.py:298\u001b[39m, in \u001b[36mAPIRequestor.request\u001b[39m\u001b[34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\n\u001b[32m    278\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    279\u001b[39m     method,\n\u001b[32m   (...)\u001b[39m\u001b[32m    286\u001b[39m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    287\u001b[39m ) -> Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    288\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.request_raw(\n\u001b[32m    289\u001b[39m         method.lower(),\n\u001b[32m    290\u001b[39m         url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    296\u001b[39m         request_timeout=request_timeout,\n\u001b[32m    297\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m     resp, got_stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    299\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m.api_key\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\GEN AI\\venv\\Lib\\site-packages\\openai\\api_requestor.py:700\u001b[39m, in \u001b[36mAPIRequestor._interpret_response\u001b[39m\u001b[34m(self, result, stream)\u001b[39m\n\u001b[32m    692\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m    693\u001b[39m         \u001b[38;5;28mself\u001b[39m._interpret_response_line(\n\u001b[32m    694\u001b[39m             line, result.status_code, result.headers, stream=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    695\u001b[39m         )\n\u001b[32m    696\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result.iter_lines())\n\u001b[32m    697\u001b[39m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m700\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    706\u001b[39m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    707\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\GEN AI\\venv\\Lib\\site-packages\\openai\\api_requestor.py:765\u001b[39m, in \u001b[36mAPIRequestor._interpret_response_line\u001b[39m\u001b[34m(self, rbody, rcode, rheaders, stream)\u001b[39m\n\u001b[32m    763\u001b[39m stream_error = stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp.data\n\u001b[32m    764\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[32m200\u001b[39m <= rcode < \u001b[32m300\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m765\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handle_error_response(\n\u001b[32m    766\u001b[39m         rbody, rcode, resp.data, rheaders, stream_error=stream_error\n\u001b[32m    767\u001b[39m     )\n\u001b[32m    768\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[31mRateLimitError\u001b[39m: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors."
     ]
    }
   ],
   "source": [
    "openai.api_key = \"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\"\n",
    "openai.ChatCompletion.create(\n",
    "model = \"gpt-3.5-turbo\",\n",
    "prompt = \"Write a poem about the beauty of nature\",\n",
    "temperature = 0.5, # Controls randomness: 0.0 is deterministic, 1.0 is very random  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82573362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9328126",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m openai.api_key = \u001b[33m\"\u001b[39m\u001b[33msk-proj-5kJz9vyZMrV9TVxCoLIh4dIVxh4GTIuu5EGC3jdGF56e-yehJeKGnxtsWXIGpahXK6oqFPEmPIT3BlbkFJ-VmtQ6kruS8VyLDAj2eeGMAWiECNka7uKYVPzPmFWohozZxUGx7c4DoNTkDrx5eFUPx1df3oQA\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4.1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43myou are an experienced Data scientist and python developer.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGive me a roadmap to become a data scientist.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.3\u001b[39;49m\n\u001b[32m      9\u001b[39m \n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\GEN AI\\venv\\Lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[39m, in \u001b[36mChatCompletion.create\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     27\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time.time() > start + timeout:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\GEN AI\\venv\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[39m, in \u001b[36mEngineAPIResource.create\u001b[39m\u001b[34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    129\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    136\u001b[39m     **params,\n\u001b[32m    137\u001b[39m ):\n\u001b[32m    138\u001b[39m     (\n\u001b[32m    139\u001b[39m         deployment_id,\n\u001b[32m    140\u001b[39m         engine,\n\u001b[32m   (...)\u001b[39m\u001b[32m    150\u001b[39m         api_key, api_base, api_type, api_version, organization, **params\n\u001b[32m    151\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     response, _, api_key = \u001b[43mrequestor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[32m    164\u001b[39m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[32m    165\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\GEN AI\\venv\\Lib\\site-packages\\openai\\api_requestor.py:298\u001b[39m, in \u001b[36mAPIRequestor.request\u001b[39m\u001b[34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\n\u001b[32m    278\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    279\u001b[39m     method,\n\u001b[32m   (...)\u001b[39m\u001b[32m    286\u001b[39m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    287\u001b[39m ) -> Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    288\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.request_raw(\n\u001b[32m    289\u001b[39m         method.lower(),\n\u001b[32m    290\u001b[39m         url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    296\u001b[39m         request_timeout=request_timeout,\n\u001b[32m    297\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m     resp, got_stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    299\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m.api_key\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\GEN AI\\venv\\Lib\\site-packages\\openai\\api_requestor.py:700\u001b[39m, in \u001b[36mAPIRequestor._interpret_response\u001b[39m\u001b[34m(self, result, stream)\u001b[39m\n\u001b[32m    692\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m    693\u001b[39m         \u001b[38;5;28mself\u001b[39m._interpret_response_line(\n\u001b[32m    694\u001b[39m             line, result.status_code, result.headers, stream=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    695\u001b[39m         )\n\u001b[32m    696\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result.iter_lines())\n\u001b[32m    697\u001b[39m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m700\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    706\u001b[39m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    707\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\GEN AI\\venv\\Lib\\site-packages\\openai\\api_requestor.py:765\u001b[39m, in \u001b[36mAPIRequestor._interpret_response_line\u001b[39m\u001b[34m(self, rbody, rcode, rheaders, stream)\u001b[39m\n\u001b[32m    763\u001b[39m stream_error = stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp.data\n\u001b[32m    764\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[32m200\u001b[39m <= rcode < \u001b[32m300\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m765\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handle_error_response(\n\u001b[32m    766\u001b[39m         rbody, rcode, resp.data, rheaders, stream_error=stream_error\n\u001b[32m    767\u001b[39m     )\n\u001b[32m    768\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[31mRateLimitError\u001b[39m: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors."
     ]
    }
   ],
   "source": [
    "openai.api_key = \"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\"\n",
    "openai.ChatCompletion.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"you are an experienced Data scientist and python developer.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Give me a roadmap to become a data scientist.\"}\n",
    "    ],\n",
    "    temperature=0.3\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8af08451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==0.28\n",
      "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in g:\\gen ai\\venv\\lib\\site-packages (from openai==0.28) (2.32.3)\n",
      "Requirement already satisfied: tqdm in g:\\gen ai\\venv\\lib\\site-packages (from openai==0.28) (4.67.1)\n",
      "Collecting aiohttp (from openai==0.28)\n",
      "  Downloading aiohttp-3.11.18-cp311-cp311-win_amd64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in g:\\gen ai\\venv\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in g:\\gen ai\\venv\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in g:\\gen ai\\venv\\lib\\site-packages (from requests>=2.20->openai==0.28) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in g:\\gen ai\\venv\\lib\\site-packages (from requests>=2.20->openai==0.28) (2025.1.31)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->openai==0.28)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->openai==0.28)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->openai==0.28)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->openai==0.28)\n",
      "  Downloading frozenlist-1.6.0-cp311-cp311-win_amd64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->openai==0.28)\n",
      "  Downloading multidict-6.4.3-cp311-cp311-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->openai==0.28)\n",
      "  Downloading propcache-0.3.1-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->openai==0.28)\n",
      "  Downloading yarl-1.20.0-cp311-cp311-win_amd64.whl.metadata (74 kB)\n",
      "Requirement already satisfied: colorama in g:\\gen ai\\venv\\lib\\site-packages (from tqdm->openai==0.28) (0.4.6)\n",
      "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "Downloading aiohttp-3.11.18-cp311-cp311-win_amd64.whl (443 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.6.0-cp311-cp311-win_amd64.whl (120 kB)\n",
      "Downloading multidict-6.4.3-cp311-cp311-win_amd64.whl (38 kB)\n",
      "Downloading propcache-0.3.1-cp311-cp311-win_amd64.whl (45 kB)\n",
      "Downloading yarl-1.20.0-cp311-cp311-win_amd64.whl (93 kB)\n",
      "Installing collected packages: propcache, multidict, frozenlist, attrs, aiohappyeyeballs, yarl, aiosignal, aiohttp, openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.76.0\n",
      "    Uninstalling openai-1.76.0:\n",
      "      Successfully uninstalled openai-1.76.0\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 attrs-25.3.0 frozenlist-1.6.0 multidict-6.4.3 openai-0.28.0 propcache-0.3.1 yarl-1.20.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai==0.28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f92857",
   "metadata": {},
   "source": [
    "# With Euri API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2ad38f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'aitxt-VINU6nTeLCyqS2Mf4veLCnLU', 'object': 'chat.completion', 'created': 1745490802, 'model': 'gemini-2.0-flash-001', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'The temperature in Dandeli, India is currently 93°F (34°C), but it feels like 104°F (40°C). There is a 35% chance of light thunderstorms and rain.\\n'}, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 14, 'completion_tokens': 51, 'total_tokens': 65}}\n",
      "The temperature in Dandeli, India is currently 93°F (34°C), but it feels like 104°F (40°C). There is a 35% chance of light thunderstorms and rain.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using requests library\n",
    "import requests\n",
    "\n",
    "def generate_completion():\n",
    "    url = \"https://api.euron.one/api/v1/euri/alpha/chat/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiJlNGU5YTY0My1lY2E0LTQ1ZjctYjIyNi0wNDdmNTMyNWVmZjAiLCJlbWFpbCI6ImNoZXRhbmZlcm5AZ21haWwuY29tIiwiaWF0IjoxNzQxMzYyNDIwLCJleHAiOjE3NzI4OTg0MjB9._Uz6sL0eJuWqgY1yw_Oarxlv8q8ZjoV9eVgee2uIwCE\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"what is today temperature in Dandeli\"\n",
    "            }\n",
    "        ],\n",
    "        \"model\": \"gemini-2.0-flash-001\",\n",
    "        \"max_tokens\": 1000,\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    data = response.json()\n",
    "    print(data)\n",
    "    print(data['choices'][0]['message']['content'])\n",
    "\n",
    "generate_completion()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
