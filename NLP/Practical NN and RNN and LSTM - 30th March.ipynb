{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2,3,4,5]\n",
    "y = [2,4,6,8,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, b1 = .1,0.0\n",
    "w2,b2 = -0.1,0.0\n",
    "w3,w4 = .1,.1\n",
    "b3 = 0.0\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return max(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deribative_relu(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to function call here. Maybe you meant '==' instead of '='? (1082925590.py, line 35)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mw1(new) = w1 - lr * dw1\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m cannot assign to function call here. Maybe you meant '==' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    total_loss = 0\n",
    "    for x,y in zip(input,output):\n",
    "        z1 = w1*x + b1\n",
    "        h1 = relu(z1)\n",
    "\n",
    "        z2 = w2*x + b2\n",
    "        h2 = relu(z2)\n",
    "\n",
    "        y_pred = h1*w3 + h2*w4 + b3\n",
    "\n",
    "        error = y_pred - y\n",
    "        loss = error**2\n",
    "        total_loss = total_loss + loss\n",
    "\n",
    "        dl_dy = 2 * error\n",
    "\n",
    "        dw3 = dl_dy * h1\n",
    "        dw4 = dl_dy * h2\n",
    "        db3 = dl_dy * b3\n",
    "\n",
    "        dh1 = dl_dy * w3\n",
    "        dh2 = dl_dy * w4\n",
    "\n",
    "\n",
    "        dz1 = dh1 * deribative_relu(z1)\n",
    "        dz2 = dh2 * deribative_relu(z2)\n",
    "\n",
    "        dw1 = dz1 * x\n",
    "        db1 = dz1\n",
    "\n",
    "        dw2 = dz2 * x\n",
    "        db2 = dz2\n",
    "\n",
    "        w1(new)= w1 - lr * dw1\n",
    "        w2(new) = w2 - lr * dw2\n",
    "        w3(new) = w3 - lr * dw3\n",
    "        w4(new) = w4 - lr * dw4\n",
    "\n",
    "        b1(new) = b1 - lr*(db1)\n",
    "\n",
    "def prediction(x):\n",
    "        z1 = w1*x + b1\n",
    "        h1 = relu(z1)\n",
    "\n",
    "        z2 = w2*x + b2\n",
    "        h2 = relu(z2)\n",
    "\n",
    "        y_output = w3*h1 + w4*h2 + b3\n",
    "        return y_output \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mprediction\u001b[49m(\u001b[32m9\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'prediction' is not defined"
     ]
    }
   ],
   "source": [
    "prediction(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.2.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in g:\\gen ai\\venv\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-5.29.4-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: setuptools in g:\\gen ai\\venv\\lib\\site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in g:\\gen ai\\venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in g:\\gen ai\\venv\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in g:\\gen ai\\venv\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.71.0-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.9.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in g:\\gen ai\\venv\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.13.0-cp311-cp311-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.1-cp311-cp311-win_amd64.whl.metadata (22 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in g:\\gen ai\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.14.1-cp311-cp311-win_amd64.whl.metadata (50 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Downloading charset_normalizer-3.4.1-cp311-cp311-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in g:\\gen ai\\venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.19.0-cp311-cp311-win_amd64.whl (375.9 MB)\n",
      "   ---------------------------------------- 0.0/375.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/375.9 MB 5.6 MB/s eta 0:01:08\n",
      "   ---------------------------------------- 1.8/375.9 MB 4.6 MB/s eta 0:01:22\n",
      "   ---------------------------------------- 2.6/375.9 MB 3.5 MB/s eta 0:01:47\n",
      "   ---------------------------------------- 3.7/375.9 MB 3.7 MB/s eta 0:01:41\n",
      "    --------------------------------------- 4.7/375.9 MB 3.9 MB/s eta 0:01:36\n",
      "    --------------------------------------- 5.5/375.9 MB 3.8 MB/s eta 0:01:38\n",
      "    --------------------------------------- 6.0/375.9 MB 3.7 MB/s eta 0:01:41\n",
      "    --------------------------------------- 6.8/375.9 MB 3.3 MB/s eta 0:01:54\n",
      "    --------------------------------------- 7.3/375.9 MB 3.1 MB/s eta 0:01:58\n",
      "    --------------------------------------- 7.6/375.9 MB 3.0 MB/s eta 0:02:03\n",
      "    --------------------------------------- 8.1/375.9 MB 2.9 MB/s eta 0:02:07\n",
      "    --------------------------------------- 8.9/375.9 MB 2.8 MB/s eta 0:02:10\n",
      "   - -------------------------------------- 10.0/375.9 MB 2.9 MB/s eta 0:02:05\n",
      "   - -------------------------------------- 10.7/375.9 MB 2.9 MB/s eta 0:02:05\n",
      "   - -------------------------------------- 11.3/375.9 MB 2.9 MB/s eta 0:02:06\n",
      "   - -------------------------------------- 12.3/375.9 MB 2.9 MB/s eta 0:02:04\n",
      "   - -------------------------------------- 13.4/375.9 MB 3.0 MB/s eta 0:02:01\n",
      "   - -------------------------------------- 14.4/375.9 MB 3.1 MB/s eta 0:01:58\n",
      "   - -------------------------------------- 15.2/375.9 MB 3.1 MB/s eta 0:01:57\n",
      "   - -------------------------------------- 15.5/375.9 MB 3.1 MB/s eta 0:01:58\n",
      "   - -------------------------------------- 16.5/375.9 MB 3.1 MB/s eta 0:01:58\n",
      "   - -------------------------------------- 17.0/375.9 MB 3.0 MB/s eta 0:01:58\n",
      "   - -------------------------------------- 17.6/375.9 MB 2.9 MB/s eta 0:02:03\n",
      "   - -------------------------------------- 18.4/375.9 MB 3.0 MB/s eta 0:02:02\n",
      "   -- ------------------------------------- 19.4/375.9 MB 2.9 MB/s eta 0:02:02\n",
      "   -- ------------------------------------- 20.4/375.9 MB 3.0 MB/s eta 0:02:00\n",
      "   -- ------------------------------------- 20.7/375.9 MB 2.9 MB/s eta 0:02:02\n",
      "   -- ------------------------------------- 21.5/375.9 MB 2.9 MB/s eta 0:02:02\n",
      "   -- ------------------------------------- 22.5/375.9 MB 3.0 MB/s eta 0:01:59\n",
      "   -- ------------------------------------- 23.3/375.9 MB 3.0 MB/s eta 0:01:58\n",
      "   -- ------------------------------------- 24.1/375.9 MB 3.0 MB/s eta 0:01:58\n",
      "   -- ------------------------------------- 24.9/375.9 MB 3.0 MB/s eta 0:01:57\n",
      "   -- ------------------------------------- 25.4/375.9 MB 2.9 MB/s eta 0:01:59\n",
      "   -- ------------------------------------- 26.2/375.9 MB 2.9 MB/s eta 0:02:01\n",
      "   -- ------------------------------------- 27.0/375.9 MB 2.9 MB/s eta 0:02:00\n",
      "   -- ------------------------------------- 28.0/375.9 MB 3.0 MB/s eta 0:01:58\n",
      "   --- ------------------------------------ 29.1/375.9 MB 3.0 MB/s eta 0:01:55\n",
      "   --- ------------------------------------ 30.1/375.9 MB 3.0 MB/s eta 0:01:54\n",
      "   --- ------------------------------------ 31.2/375.9 MB 3.1 MB/s eta 0:01:52\n",
      "   --- ------------------------------------ 32.2/375.9 MB 3.1 MB/s eta 0:01:50\n",
      "   --- ------------------------------------ 33.0/375.9 MB 3.1 MB/s eta 0:01:50\n",
      "   --- ------------------------------------ 33.8/375.9 MB 3.1 MB/s eta 0:01:49\n",
      "   --- ------------------------------------ 34.9/375.9 MB 3.2 MB/s eta 0:01:48\n",
      "   --- ------------------------------------ 35.7/375.9 MB 3.2 MB/s eta 0:01:47\n",
      "   --- ------------------------------------ 36.7/375.9 MB 3.2 MB/s eta 0:01:46\n",
      "   ---- ----------------------------------- 37.7/375.9 MB 3.2 MB/s eta 0:01:45\n",
      "   ---- ----------------------------------- 38.5/375.9 MB 3.3 MB/s eta 0:01:44\n",
      "   ---- ----------------------------------- 39.8/375.9 MB 3.3 MB/s eta 0:01:42\n",
      "   ---- ----------------------------------- 40.6/375.9 MB 3.3 MB/s eta 0:01:42\n",
      "   ---- ----------------------------------- 41.4/375.9 MB 3.3 MB/s eta 0:01:43\n",
      "   ---- ----------------------------------- 41.9/375.9 MB 3.2 MB/s eta 0:01:44\n",
      "   ---- ----------------------------------- 42.5/375.9 MB 3.2 MB/s eta 0:01:44\n",
      "   ---- ----------------------------------- 43.5/375.9 MB 3.2 MB/s eta 0:01:44\n",
      "   ---- ----------------------------------- 44.3/375.9 MB 3.2 MB/s eta 0:01:44\n",
      "   ---- ----------------------------------- 45.1/375.9 MB 3.2 MB/s eta 0:01:44\n",
      "   ---- ----------------------------------- 45.9/375.9 MB 3.2 MB/s eta 0:01:43\n",
      "   ----- ---------------------------------- 47.2/375.9 MB 3.3 MB/s eta 0:01:42\n",
      "   ----- ---------------------------------- 47.7/375.9 MB 3.2 MB/s eta 0:01:42\n",
      "   ----- ---------------------------------- 48.0/375.9 MB 3.2 MB/s eta 0:01:43\n",
      "   ----- ---------------------------------- 48.2/375.9 MB 3.2 MB/s eta 0:01:43\n",
      "   ----- ---------------------------------- 49.0/375.9 MB 3.2 MB/s eta 0:01:44\n",
      "   ----- ---------------------------------- 49.8/375.9 MB 3.2 MB/s eta 0:01:43\n",
      "   ----- ---------------------------------- 50.6/375.9 MB 3.2 MB/s eta 0:01:43\n",
      "   ----- ---------------------------------- 51.4/375.9 MB 3.2 MB/s eta 0:01:42\n",
      "   ----- ---------------------------------- 51.9/375.9 MB 3.2 MB/s eta 0:01:42\n",
      "   ----- ---------------------------------- 53.0/375.9 MB 3.2 MB/s eta 0:01:41\n",
      "   ----- ---------------------------------- 54.3/375.9 MB 3.2 MB/s eta 0:01:40\n",
      "   ----- ---------------------------------- 55.1/375.9 MB 3.2 MB/s eta 0:01:40\n",
      "   ----- ---------------------------------- 55.8/375.9 MB 3.2 MB/s eta 0:01:39\n",
      "   ----- ---------------------------------- 56.4/375.9 MB 3.3 MB/s eta 0:01:39\n",
      "   ------ --------------------------------- 56.9/375.9 MB 3.2 MB/s eta 0:01:40\n",
      "   ------ --------------------------------- 57.9/375.9 MB 3.2 MB/s eta 0:01:39\n",
      "   ------ --------------------------------- 59.0/375.9 MB 3.2 MB/s eta 0:01:38\n",
      "   ------ --------------------------------- 59.2/375.9 MB 3.2 MB/s eta 0:01:39\n",
      "   ------ --------------------------------- 60.0/375.9 MB 3.2 MB/s eta 0:01:39\n",
      "   ------ --------------------------------- 60.6/375.9 MB 3.2 MB/s eta 0:01:39\n",
      "   ------ --------------------------------- 61.9/375.9 MB 3.2 MB/s eta 0:01:38\n",
      "   ------ --------------------------------- 62.7/375.9 MB 3.2 MB/s eta 0:01:37\n",
      "   ------ --------------------------------- 63.4/375.9 MB 3.2 MB/s eta 0:01:37\n",
      "   ------ --------------------------------- 64.5/375.9 MB 3.3 MB/s eta 0:01:36\n",
      "   ------- -------------------------------- 65.8/375.9 MB 3.3 MB/s eta 0:01:35\n",
      "   ------- -------------------------------- 66.8/375.9 MB 3.3 MB/s eta 0:01:34\n",
      "   ------- -------------------------------- 67.6/375.9 MB 3.3 MB/s eta 0:01:34\n",
      "   ------- -------------------------------- 68.7/375.9 MB 3.3 MB/s eta 0:01:33\n",
      "   ------- -------------------------------- 69.7/375.9 MB 3.3 MB/s eta 0:01:32\n",
      "   ------- -------------------------------- 70.5/375.9 MB 3.3 MB/s eta 0:01:32\n",
      "   ------- -------------------------------- 71.6/375.9 MB 3.4 MB/s eta 0:01:31\n",
      "   ------- -------------------------------- 72.6/375.9 MB 3.4 MB/s eta 0:01:31\n",
      "   ------- -------------------------------- 73.4/375.9 MB 3.4 MB/s eta 0:01:30\n",
      "   ------- -------------------------------- 74.4/375.9 MB 3.4 MB/s eta 0:01:30\n",
      "   ------- -------------------------------- 74.7/375.9 MB 3.3 MB/s eta 0:01:30\n",
      "   ------- -------------------------------- 75.0/375.9 MB 3.3 MB/s eta 0:01:31\n",
      "   -------- ------------------------------- 75.8/375.9 MB 3.3 MB/s eta 0:01:31\n",
      "   -------- ------------------------------- 76.5/375.9 MB 3.3 MB/s eta 0:01:31\n",
      "   -------- ------------------------------- 77.3/375.9 MB 3.3 MB/s eta 0:01:31\n",
      "   -------- ------------------------------- 77.9/375.9 MB 3.3 MB/s eta 0:01:31\n",
      "   -------- ------------------------------- 78.6/375.9 MB 3.3 MB/s eta 0:01:30\n",
      "   -------- ------------------------------- 79.4/375.9 MB 3.3 MB/s eta 0:01:30\n",
      "   -------- ------------------------------- 80.5/375.9 MB 3.3 MB/s eta 0:01:30\n",
      "   -------- ------------------------------- 81.0/375.9 MB 3.3 MB/s eta 0:01:30\n",
      "   -------- ------------------------------- 82.1/375.9 MB 3.3 MB/s eta 0:01:29\n",
      "   -------- ------------------------------- 83.4/375.9 MB 3.3 MB/s eta 0:01:28\n",
      "   -------- ------------------------------- 84.1/375.9 MB 3.3 MB/s eta 0:01:28\n",
      "   --------- ------------------------------ 84.9/375.9 MB 3.3 MB/s eta 0:01:28\n",
      "   --------- ------------------------------ 86.2/375.9 MB 3.4 MB/s eta 0:01:27\n",
      "   --------- ------------------------------ 87.0/375.9 MB 3.4 MB/s eta 0:01:27\n",
      "   --------- ------------------------------ 87.8/375.9 MB 3.4 MB/s eta 0:01:26\n",
      "   --------- ------------------------------ 88.9/375.9 MB 3.4 MB/s eta 0:01:26\n",
      "   --------- ------------------------------ 89.9/375.9 MB 3.3 MB/s eta 0:01:26\n",
      "   --------- ------------------------------ 90.7/375.9 MB 3.3 MB/s eta 0:01:27\n",
      "   --------- ------------------------------ 91.5/375.9 MB 3.3 MB/s eta 0:01:26\n",
      "   --------- ------------------------------ 92.5/375.9 MB 3.3 MB/s eta 0:01:26\n",
      "   --------- ------------------------------ 93.1/375.9 MB 3.3 MB/s eta 0:01:26\n",
      "   ---------- ----------------------------- 94.1/375.9 MB 3.3 MB/s eta 0:01:26\n",
      "   ---------- ----------------------------- 94.9/375.9 MB 3.3 MB/s eta 0:01:25\n",
      "   ---------- ----------------------------- 96.2/375.9 MB 3.3 MB/s eta 0:01:25\n",
      "   ---------- ----------------------------- 96.7/375.9 MB 3.3 MB/s eta 0:01:25\n",
      "   ---------- ----------------------------- 97.5/375.9 MB 3.3 MB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 98.3/375.9 MB 3.3 MB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 99.4/375.9 MB 3.3 MB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 100.1/375.9 MB 3.3 MB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 101.2/375.9 MB 3.3 MB/s eta 0:01:23\n",
      "   ---------- ----------------------------- 102.2/375.9 MB 3.3 MB/s eta 0:01:22\n",
      "   ---------- ----------------------------- 103.3/375.9 MB 3.4 MB/s eta 0:01:22\n",
      "   ----------- ---------------------------- 104.3/375.9 MB 3.4 MB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 105.4/375.9 MB 3.4 MB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 106.4/375.9 MB 3.4 MB/s eta 0:01:20\n",
      "   ----------- ---------------------------- 107.2/375.9 MB 3.4 MB/s eta 0:01:20\n",
      "   ----------- ---------------------------- 108.3/375.9 MB 3.4 MB/s eta 0:01:19\n",
      "   ----------- ---------------------------- 109.3/375.9 MB 3.4 MB/s eta 0:01:18\n",
      "   ----------- ---------------------------- 110.1/375.9 MB 3.4 MB/s eta 0:01:18\n",
      "   ----------- ---------------------------- 110.9/375.9 MB 3.4 MB/s eta 0:01:17\n",
      "   ----------- ---------------------------- 111.7/375.9 MB 3.5 MB/s eta 0:01:17\n",
      "   ----------- ---------------------------- 111.7/375.9 MB 3.5 MB/s eta 0:01:17\n",
      "   ----------- ---------------------------- 112.5/375.9 MB 3.4 MB/s eta 0:01:17\n",
      "   ------------ --------------------------- 113.5/375.9 MB 3.5 MB/s eta 0:01:17\n",
      "   ------------ --------------------------- 114.3/375.9 MB 3.5 MB/s eta 0:01:16\n",
      "   ------------ --------------------------- 115.1/375.9 MB 3.5 MB/s eta 0:01:16\n",
      "   ------------ --------------------------- 115.6/375.9 MB 3.5 MB/s eta 0:01:16\n",
      "   ------------ --------------------------- 116.9/375.9 MB 3.5 MB/s eta 0:01:15\n",
      "   ------------ --------------------------- 117.4/375.9 MB 3.4 MB/s eta 0:01:16\n",
      "   ------------ --------------------------- 118.2/375.9 MB 3.4 MB/s eta 0:01:16\n",
      "   ------------ --------------------------- 118.8/375.9 MB 3.4 MB/s eta 0:01:16\n",
      "   ------------ --------------------------- 119.5/375.9 MB 3.4 MB/s eta 0:01:15\n",
      "   ------------ --------------------------- 120.6/375.9 MB 3.5 MB/s eta 0:01:14\n",
      "   ------------ --------------------------- 121.6/375.9 MB 3.5 MB/s eta 0:01:14\n",
      "   ------------- -------------------------- 122.4/375.9 MB 3.5 MB/s eta 0:01:14\n",
      "   ------------- -------------------------- 123.7/375.9 MB 3.5 MB/s eta 0:01:12\n",
      "   ------------- -------------------------- 124.5/375.9 MB 3.5 MB/s eta 0:01:13\n",
      "   ------------- -------------------------- 125.0/375.9 MB 3.5 MB/s eta 0:01:13\n",
      "   ------------- -------------------------- 125.3/375.9 MB 3.5 MB/s eta 0:01:13\n",
      "   ------------- -------------------------- 126.4/375.9 MB 3.5 MB/s eta 0:01:13\n",
      "   ------------- -------------------------- 126.9/375.9 MB 3.4 MB/s eta 0:01:13\n",
      "   ------------- -------------------------- 127.9/375.9 MB 3.5 MB/s eta 0:01:12\n",
      "   ------------- -------------------------- 129.0/375.9 MB 3.5 MB/s eta 0:01:12\n",
      "   ------------- -------------------------- 130.0/375.9 MB 3.5 MB/s eta 0:01:11\n",
      "   ------------- -------------------------- 131.1/375.9 MB 3.5 MB/s eta 0:01:10\n",
      "   -------------- ------------------------- 132.1/375.9 MB 3.5 MB/s eta 0:01:09\n",
      "   -------------- ------------------------- 133.4/375.9 MB 3.6 MB/s eta 0:01:09\n",
      "   -------------- ------------------------- 134.2/375.9 MB 3.6 MB/s eta 0:01:09\n",
      "   -------------- ------------------------- 135.0/375.9 MB 3.5 MB/s eta 0:01:09\n",
      "   -------------- ------------------------- 136.3/375.9 MB 3.5 MB/s eta 0:01:08\n",
      "   -------------- ------------------------- 137.4/375.9 MB 3.6 MB/s eta 0:01:08\n",
      "   -------------- ------------------------- 138.4/375.9 MB 3.6 MB/s eta 0:01:07\n",
      "   -------------- ------------------------- 139.2/375.9 MB 3.5 MB/s eta 0:01:07\n",
      "   -------------- ------------------------- 140.5/375.9 MB 3.6 MB/s eta 0:01:07\n",
      "   --------------- ------------------------ 141.6/375.9 MB 3.6 MB/s eta 0:01:06\n",
      "   --------------- ------------------------ 142.3/375.9 MB 3.6 MB/s eta 0:01:06\n",
      "   --------------- ------------------------ 143.1/375.9 MB 3.6 MB/s eta 0:01:06\n",
      "   --------------- ------------------------ 144.4/375.9 MB 3.6 MB/s eta 0:01:05\n",
      "   --------------- ------------------------ 145.2/375.9 MB 3.6 MB/s eta 0:01:05\n",
      "   --------------- ------------------------ 146.5/375.9 MB 3.6 MB/s eta 0:01:05\n",
      "   --------------- ------------------------ 147.3/375.9 MB 3.6 MB/s eta 0:01:04\n",
      "   --------------- ------------------------ 148.1/375.9 MB 3.6 MB/s eta 0:01:04\n",
      "   --------------- ------------------------ 148.9/375.9 MB 3.6 MB/s eta 0:01:04\n",
      "   --------------- ------------------------ 149.2/375.9 MB 3.6 MB/s eta 0:01:04\n",
      "   --------------- ------------------------ 149.7/375.9 MB 3.6 MB/s eta 0:01:04\n",
      "   ---------------- ----------------------- 150.5/375.9 MB 3.6 MB/s eta 0:01:03\n",
      "   ---------------- ----------------------- 151.3/375.9 MB 3.6 MB/s eta 0:01:03\n",
      "   ---------------- ----------------------- 152.3/375.9 MB 3.6 MB/s eta 0:01:03\n",
      "   ---------------- ----------------------- 153.1/375.9 MB 3.6 MB/s eta 0:01:02\n",
      "   ---------------- ----------------------- 154.4/375.9 MB 3.6 MB/s eta 0:01:01\n",
      "   ---------------- ----------------------- 155.2/375.9 MB 3.6 MB/s eta 0:01:01\n",
      "   ---------------- ----------------------- 156.0/375.9 MB 3.6 MB/s eta 0:01:01\n",
      "   ---------------- ----------------------- 156.8/375.9 MB 3.6 MB/s eta 0:01:01\n",
      "   ---------------- ----------------------- 157.8/375.9 MB 3.7 MB/s eta 0:01:00\n",
      "   ---------------- ----------------------- 159.1/375.9 MB 3.7 MB/s eta 0:00:59\n",
      "   ----------------- ---------------------- 160.2/375.9 MB 3.7 MB/s eta 0:00:59\n",
      "   ----------------- ---------------------- 161.0/375.9 MB 3.7 MB/s eta 0:00:59\n",
      "   ----------------- ---------------------- 161.7/375.9 MB 3.7 MB/s eta 0:00:58\n",
      "   ----------------- ---------------------- 162.8/375.9 MB 3.7 MB/s eta 0:00:58\n",
      "   ----------------- ---------------------- 163.8/375.9 MB 3.7 MB/s eta 0:00:57\n",
      "   ----------------- ---------------------- 164.9/375.9 MB 3.7 MB/s eta 0:00:57\n",
      "   ----------------- ---------------------- 165.9/375.9 MB 3.7 MB/s eta 0:00:57\n",
      "   ----------------- ---------------------- 167.2/375.9 MB 3.7 MB/s eta 0:00:56\n",
      "   ----------------- ---------------------- 168.0/375.9 MB 3.7 MB/s eta 0:00:56\n",
      "   ----------------- ---------------------- 168.8/375.9 MB 3.8 MB/s eta 0:00:56\n",
      "   ------------------ --------------------- 169.9/375.9 MB 3.8 MB/s eta 0:00:55\n",
      "   ------------------ --------------------- 170.4/375.9 MB 3.7 MB/s eta 0:00:56\n",
      "   ------------------ --------------------- 171.2/375.9 MB 3.7 MB/s eta 0:00:55\n",
      "   ------------------ --------------------- 172.2/375.9 MB 3.8 MB/s eta 0:00:55\n",
      "   ------------------ --------------------- 173.3/375.9 MB 3.8 MB/s eta 0:00:54\n",
      "   ------------------ --------------------- 174.3/375.9 MB 3.8 MB/s eta 0:00:54\n",
      "   ------------------ --------------------- 175.4/375.9 MB 3.8 MB/s eta 0:00:54\n",
      "   ------------------ --------------------- 176.2/375.9 MB 3.8 MB/s eta 0:00:54\n",
      "   ------------------ --------------------- 176.9/375.9 MB 3.8 MB/s eta 0:00:53\n",
      "   ------------------ --------------------- 178.3/375.9 MB 3.8 MB/s eta 0:00:53\n",
      "   ------------------- -------------------- 179.0/375.9 MB 3.8 MB/s eta 0:00:53\n",
      "   ------------------- -------------------- 179.8/375.9 MB 3.8 MB/s eta 0:00:53\n",
      "   ------------------- -------------------- 180.9/375.9 MB 3.8 MB/s eta 0:00:52\n",
      "   ------------------- -------------------- 181.9/375.9 MB 3.8 MB/s eta 0:00:52\n",
      "   ------------------- -------------------- 183.0/375.9 MB 3.8 MB/s eta 0:00:52\n",
      "   ------------------- -------------------- 184.0/375.9 MB 3.8 MB/s eta 0:00:51\n",
      "   ------------------- -------------------- 185.1/375.9 MB 3.8 MB/s eta 0:00:51\n",
      "   ------------------- -------------------- 185.9/375.9 MB 3.8 MB/s eta 0:00:51\n",
      "   ------------------- -------------------- 186.9/375.9 MB 3.8 MB/s eta 0:00:50\n",
      "   -------------------- ------------------- 188.2/375.9 MB 3.8 MB/s eta 0:00:50\n",
      "   -------------------- ------------------- 189.0/375.9 MB 3.8 MB/s eta 0:00:49\n",
      "   -------------------- ------------------- 189.5/375.9 MB 3.8 MB/s eta 0:00:49\n",
      "   -------------------- ------------------- 190.6/375.9 MB 3.8 MB/s eta 0:00:49\n",
      "   -------------------- ------------------- 191.4/375.9 MB 3.8 MB/s eta 0:00:48\n",
      "   -------------------- ------------------- 191.9/375.9 MB 3.8 MB/s eta 0:00:48\n",
      "   -------------------- ------------------- 193.2/375.9 MB 3.9 MB/s eta 0:00:48\n",
      "   -------------------- ------------------- 194.0/375.9 MB 3.9 MB/s eta 0:00:47\n",
      "   -------------------- ------------------- 194.8/375.9 MB 3.9 MB/s eta 0:00:47\n",
      "   -------------------- ------------------- 195.8/375.9 MB 3.9 MB/s eta 0:00:47\n",
      "   -------------------- ------------------- 196.9/375.9 MB 3.9 MB/s eta 0:00:46\n",
      "   --------------------- ------------------ 198.2/375.9 MB 3.9 MB/s eta 0:00:46\n",
      "   --------------------- ------------------ 198.7/375.9 MB 3.9 MB/s eta 0:00:46\n",
      "   --------------------- ------------------ 199.8/375.9 MB 3.9 MB/s eta 0:00:46\n",
      "   --------------------- ------------------ 200.8/375.9 MB 3.9 MB/s eta 0:00:45\n",
      "   --------------------- ------------------ 201.9/375.9 MB 3.9 MB/s eta 0:00:45\n",
      "   --------------------- ------------------ 202.9/375.9 MB 3.9 MB/s eta 0:00:45\n",
      "   --------------------- ------------------ 203.9/375.9 MB 3.9 MB/s eta 0:00:44\n",
      "   --------------------- ------------------ 204.7/375.9 MB 3.9 MB/s eta 0:00:44\n",
      "   --------------------- ------------------ 205.8/375.9 MB 3.9 MB/s eta 0:00:44\n",
      "   ---------------------- ----------------- 207.1/375.9 MB 3.9 MB/s eta 0:00:43\n",
      "   ---------------------- ----------------- 207.6/375.9 MB 4.0 MB/s eta 0:00:43\n",
      "   ---------------------- ----------------- 208.1/375.9 MB 4.0 MB/s eta 0:00:43\n",
      "   ---------------------- ----------------- 208.7/375.9 MB 4.0 MB/s eta 0:00:43\n",
      "   ---------------------- ----------------- 209.7/375.9 MB 4.0 MB/s eta 0:00:42\n",
      "   ---------------------- ----------------- 210.8/375.9 MB 4.0 MB/s eta 0:00:42\n",
      "   ---------------------- ----------------- 211.8/375.9 MB 4.0 MB/s eta 0:00:42\n",
      "   ---------------------- ----------------- 212.3/375.9 MB 4.0 MB/s eta 0:00:41\n",
      "   ---------------------- ----------------- 212.9/375.9 MB 4.0 MB/s eta 0:00:41\n",
      "   ---------------------- ----------------- 213.6/375.9 MB 4.0 MB/s eta 0:00:41\n",
      "   ---------------------- ----------------- 214.7/375.9 MB 4.0 MB/s eta 0:00:41\n",
      "   ---------------------- ----------------- 216.0/375.9 MB 4.0 MB/s eta 0:00:40\n",
      "   ----------------------- ---------------- 217.1/375.9 MB 4.0 MB/s eta 0:00:40\n",
      "   ----------------------- ---------------- 217.8/375.9 MB 4.0 MB/s eta 0:00:40\n",
      "   ----------------------- ---------------- 218.4/375.9 MB 4.0 MB/s eta 0:00:40\n",
      "   ----------------------- ---------------- 219.4/375.9 MB 4.1 MB/s eta 0:00:39\n",
      "   ----------------------- ---------------- 220.5/375.9 MB 4.1 MB/s eta 0:00:39\n",
      "   ----------------------- ---------------- 221.2/375.9 MB 4.1 MB/s eta 0:00:39\n",
      "   ----------------------- ---------------- 222.0/375.9 MB 4.0 MB/s eta 0:00:39\n",
      "   ----------------------- ---------------- 223.1/375.9 MB 4.0 MB/s eta 0:00:38\n",
      "   ----------------------- ---------------- 224.1/375.9 MB 4.0 MB/s eta 0:00:38\n",
      "   ----------------------- ---------------- 225.2/375.9 MB 4.0 MB/s eta 0:00:38\n",
      "   ------------------------ --------------- 226.2/375.9 MB 4.0 MB/s eta 0:00:37\n",
      "   ------------------------ --------------- 227.3/375.9 MB 4.0 MB/s eta 0:00:37\n",
      "   ------------------------ --------------- 227.8/375.9 MB 4.0 MB/s eta 0:00:37\n",
      "   ------------------------ --------------- 228.6/375.9 MB 4.0 MB/s eta 0:00:37\n",
      "   ------------------------ --------------- 229.6/375.9 MB 4.0 MB/s eta 0:00:37\n",
      "   ------------------------ --------------- 230.7/375.9 MB 4.0 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 231.5/375.9 MB 4.0 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 232.0/375.9 MB 4.0 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 232.8/375.9 MB 4.1 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 233.6/375.9 MB 4.1 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 234.4/375.9 MB 4.0 MB/s eta 0:00:35\n",
      "   ------------------------- -------------- 235.1/375.9 MB 4.0 MB/s eta 0:00:36\n",
      "   ------------------------- -------------- 235.7/375.9 MB 4.0 MB/s eta 0:00:35\n",
      "   ------------------------- -------------- 236.7/375.9 MB 4.0 MB/s eta 0:00:35\n",
      "   ------------------------- -------------- 237.5/375.9 MB 4.0 MB/s eta 0:00:35\n",
      "   ------------------------- -------------- 238.0/375.9 MB 4.0 MB/s eta 0:00:35\n",
      "   ------------------------- -------------- 238.8/375.9 MB 4.0 MB/s eta 0:00:34\n",
      "   ------------------------- -------------- 239.3/375.9 MB 4.0 MB/s eta 0:00:34\n",
      "   ------------------------- -------------- 240.4/375.9 MB 4.0 MB/s eta 0:00:34\n",
      "   ------------------------- -------------- 241.4/375.9 MB 4.0 MB/s eta 0:00:34\n",
      "   ------------------------- -------------- 241.7/375.9 MB 4.0 MB/s eta 0:00:34\n",
      "   ------------------------- -------------- 242.2/375.9 MB 4.0 MB/s eta 0:00:34\n",
      "   ------------------------- -------------- 243.3/375.9 MB 4.0 MB/s eta 0:00:34\n",
      "   ------------------------- -------------- 244.3/375.9 MB 4.0 MB/s eta 0:00:33\n",
      "   -------------------------- ------------- 245.1/375.9 MB 4.0 MB/s eta 0:00:33\n",
      "   -------------------------- ------------- 246.4/375.9 MB 4.1 MB/s eta 0:00:32\n",
      "   -------------------------- ------------- 247.2/375.9 MB 4.1 MB/s eta 0:00:32\n",
      "   -------------------------- ------------- 248.5/375.9 MB 4.1 MB/s eta 0:00:32\n",
      "   -------------------------- ------------- 249.0/375.9 MB 4.1 MB/s eta 0:00:32\n",
      "   -------------------------- ------------- 250.1/375.9 MB 4.1 MB/s eta 0:00:31\n",
      "   -------------------------- ------------- 251.1/375.9 MB 4.1 MB/s eta 0:00:31\n",
      "   -------------------------- ------------- 252.2/375.9 MB 4.1 MB/s eta 0:00:31\n",
      "   -------------------------- ------------- 252.7/375.9 MB 4.1 MB/s eta 0:00:31\n",
      "   -------------------------- ------------- 253.5/375.9 MB 4.1 MB/s eta 0:00:31\n",
      "   --------------------------- ------------ 254.5/375.9 MB 4.0 MB/s eta 0:00:30\n",
      "   --------------------------- ------------ 255.6/375.9 MB 4.1 MB/s eta 0:00:30\n",
      "   --------------------------- ------------ 256.6/375.9 MB 4.1 MB/s eta 0:00:30\n",
      "   --------------------------- ------------ 257.7/375.9 MB 4.1 MB/s eta 0:00:30\n",
      "   --------------------------- ------------ 258.7/375.9 MB 4.0 MB/s eta 0:00:29\n",
      "   --------------------------- ------------ 259.8/375.9 MB 4.1 MB/s eta 0:00:29\n",
      "   --------------------------- ------------ 260.6/375.9 MB 4.1 MB/s eta 0:00:29\n",
      "   --------------------------- ------------ 261.4/375.9 MB 4.0 MB/s eta 0:00:29\n",
      "   --------------------------- ------------ 262.4/375.9 MB 4.0 MB/s eta 0:00:29\n",
      "   ---------------------------- ----------- 263.7/375.9 MB 4.1 MB/s eta 0:00:28\n",
      "   ---------------------------- ----------- 264.5/375.9 MB 4.1 MB/s eta 0:00:28\n",
      "   ---------------------------- ----------- 265.3/375.9 MB 4.0 MB/s eta 0:00:28\n",
      "   ---------------------------- ----------- 266.6/375.9 MB 4.1 MB/s eta 0:00:27\n",
      "   ---------------------------- ----------- 267.4/375.9 MB 4.0 MB/s eta 0:00:27\n",
      "   ---------------------------- ----------- 268.2/375.9 MB 4.0 MB/s eta 0:00:27\n",
      "   ---------------------------- ----------- 269.0/375.9 MB 4.0 MB/s eta 0:00:27\n",
      "   ---------------------------- ----------- 270.0/375.9 MB 4.1 MB/s eta 0:00:27\n",
      "   ---------------------------- ----------- 271.1/375.9 MB 4.1 MB/s eta 0:00:26\n",
      "   ---------------------------- ----------- 271.6/375.9 MB 4.1 MB/s eta 0:00:26\n",
      "   ----------------------------- ---------- 272.6/375.9 MB 4.1 MB/s eta 0:00:26\n",
      "   ----------------------------- ---------- 273.7/375.9 MB 4.1 MB/s eta 0:00:25\n",
      "   ----------------------------- ---------- 274.7/375.9 MB 4.1 MB/s eta 0:00:25\n",
      "   ----------------------------- ---------- 275.5/375.9 MB 4.1 MB/s eta 0:00:25\n",
      "   ----------------------------- ---------- 276.6/375.9 MB 4.1 MB/s eta 0:00:25\n",
      "   ----------------------------- ---------- 277.9/375.9 MB 4.1 MB/s eta 0:00:24\n",
      "   ----------------------------- ---------- 278.7/375.9 MB 4.1 MB/s eta 0:00:24\n",
      "   ----------------------------- ---------- 279.4/375.9 MB 4.1 MB/s eta 0:00:24\n",
      "   ----------------------------- ---------- 280.8/375.9 MB 4.1 MB/s eta 0:00:24\n",
      "   ----------------------------- ---------- 281.8/375.9 MB 4.1 MB/s eta 0:00:23\n",
      "   ------------------------------ --------- 282.9/375.9 MB 4.1 MB/s eta 0:00:23\n",
      "   ------------------------------ --------- 283.6/375.9 MB 4.1 MB/s eta 0:00:23\n",
      "   ------------------------------ --------- 284.4/375.9 MB 4.1 MB/s eta 0:00:23\n",
      "   ------------------------------ --------- 285.5/375.9 MB 4.1 MB/s eta 0:00:22\n",
      "   ------------------------------ --------- 286.8/375.9 MB 4.1 MB/s eta 0:00:22\n",
      "   ------------------------------ --------- 287.6/375.9 MB 4.1 MB/s eta 0:00:22\n",
      "   ------------------------------ --------- 288.4/375.9 MB 4.1 MB/s eta 0:00:22\n",
      "   ------------------------------ --------- 289.4/375.9 MB 4.1 MB/s eta 0:00:22\n",
      "   ------------------------------ --------- 290.5/375.9 MB 4.1 MB/s eta 0:00:21\n",
      "   ------------------------------- -------- 291.5/375.9 MB 4.1 MB/s eta 0:00:21\n",
      "   ------------------------------- -------- 292.6/375.9 MB 4.1 MB/s eta 0:00:21\n",
      "   ------------------------------- -------- 293.3/375.9 MB 4.1 MB/s eta 0:00:20\n",
      "   ------------------------------- -------- 294.1/375.9 MB 4.1 MB/s eta 0:00:20\n",
      "   ------------------------------- -------- 294.9/375.9 MB 4.1 MB/s eta 0:00:20\n",
      "   ------------------------------- -------- 295.7/375.9 MB 4.2 MB/s eta 0:00:20\n",
      "   ------------------------------- -------- 297.0/375.9 MB 4.2 MB/s eta 0:00:19\n",
      "   ------------------------------- -------- 297.5/375.9 MB 4.2 MB/s eta 0:00:19\n",
      "   ------------------------------- -------- 298.1/375.9 MB 4.1 MB/s eta 0:00:19\n",
      "   ------------------------------- -------- 298.8/375.9 MB 4.1 MB/s eta 0:00:19\n",
      "   ------------------------------- -------- 299.6/375.9 MB 4.1 MB/s eta 0:00:19\n",
      "   -------------------------------- ------- 300.9/375.9 MB 4.1 MB/s eta 0:00:19\n",
      "   -------------------------------- ------- 302.0/375.9 MB 4.1 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 303.0/375.9 MB 4.1 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 303.6/375.9 MB 4.1 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 304.6/375.9 MB 4.1 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 305.4/375.9 MB 4.1 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 306.7/375.9 MB 4.1 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 307.8/375.9 MB 4.1 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 308.5/375.9 MB 4.1 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 309.6/375.9 MB 4.1 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 310.9/375.9 MB 4.1 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 311.7/375.9 MB 4.1 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 312.5/375.9 MB 4.1 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 313.5/375.9 MB 4.1 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 314.8/375.9 MB 4.2 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 315.4/375.9 MB 4.2 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 316.1/375.9 MB 4.2 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 317.5/375.9 MB 4.2 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 318.2/375.9 MB 4.2 MB/s eta 0:00:14\n",
      "   --------------------------------- ------ 319.3/375.9 MB 4.2 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 320.3/375.9 MB 4.2 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 321.4/375.9 MB 4.2 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 322.2/375.9 MB 4.2 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 323.2/375.9 MB 4.2 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 324.3/375.9 MB 4.2 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 325.6/375.9 MB 4.2 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 326.4/375.9 MB 4.2 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 327.4/375.9 MB 4.2 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 328.5/375.9 MB 4.2 MB/s eta 0:00:12\n",
      "   ----------------------------------- ---- 329.5/375.9 MB 4.2 MB/s eta 0:00:12\n",
      "   ----------------------------------- ---- 330.3/375.9 MB 4.2 MB/s eta 0:00:11\n",
      "   ----------------------------------- ---- 331.1/375.9 MB 4.2 MB/s eta 0:00:11\n",
      "   ----------------------------------- ---- 332.4/375.9 MB 4.2 MB/s eta 0:00:11\n",
      "   ----------------------------------- ---- 333.4/375.9 MB 4.2 MB/s eta 0:00:11\n",
      "   ----------------------------------- ---- 334.5/375.9 MB 4.2 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 335.5/375.9 MB 4.2 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 336.6/375.9 MB 4.2 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 337.4/375.9 MB 4.2 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 337.9/375.9 MB 4.2 MB/s eta 0:00:10\n",
      "   ------------------------------------ --- 338.7/375.9 MB 4.2 MB/s eta 0:00:09\n",
      "   ------------------------------------ --- 339.2/375.9 MB 4.2 MB/s eta 0:00:09\n",
      "   ------------------------------------ --- 340.0/375.9 MB 4.2 MB/s eta 0:00:09\n",
      "   ------------------------------------ --- 341.0/375.9 MB 4.2 MB/s eta 0:00:09\n",
      "   ------------------------------------ --- 342.1/375.9 MB 4.2 MB/s eta 0:00:09\n",
      "   ------------------------------------ --- 343.1/375.9 MB 4.2 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 343.7/375.9 MB 4.2 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 344.7/375.9 MB 4.2 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 345.8/375.9 MB 4.2 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 346.6/375.9 MB 4.2 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 347.3/375.9 MB 4.2 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 347.9/375.9 MB 4.2 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 348.9/375.9 MB 4.2 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 349.4/375.9 MB 4.1 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 350.5/375.9 MB 4.1 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 351.5/375.9 MB 4.1 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 352.1/375.9 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 352.8/375.9 MB 4.1 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 353.9/375.9 MB 4.1 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 355.2/375.9 MB 4.1 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 355.5/375.9 MB 4.1 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 356.0/375.9 MB 4.1 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 356.5/375.9 MB 4.1 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 357.6/375.9 MB 4.1 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 358.6/375.9 MB 4.1 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 359.1/375.9 MB 4.2 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 360.4/375.9 MB 4.2 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 361.2/375.9 MB 4.2 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 362.5/375.9 MB 4.2 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 362.8/375.9 MB 4.2 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 363.3/375.9 MB 4.2 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 364.4/375.9 MB 4.2 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 365.2/375.9 MB 4.2 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 366.0/375.9 MB 4.2 MB/s eta 0:00:03\n",
      "   ---------------------------------------  367.3/375.9 MB 4.2 MB/s eta 0:00:03\n",
      "   ---------------------------------------  368.1/375.9 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------------------------------  368.6/375.9 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------------------------------  369.4/375.9 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------------------------------  370.7/375.9 MB 4.3 MB/s eta 0:00:02\n",
      "   ---------------------------------------  371.5/375.9 MB 4.3 MB/s eta 0:00:02\n",
      "   ---------------------------------------  372.5/375.9 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  373.6/375.9 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  374.1/375.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  374.6/375.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.4/375.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 375.9/375.9 MB 3.3 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.2.1-py3-none-any.whl (277 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.71.0-cp311-cp311-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 1.0/4.3 MB 5.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.8/4.3 MB 4.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 3.1/4.3 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.2/4.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.2/4.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.2/4.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 2.6 MB/s eta 0:00:00\n",
      "Downloading h5py-3.13.0-cp311-cp311-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.8/3.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.1/3.0 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.9/3.0 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.9/3.0 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.0/3.0 MB 2.5 MB/s eta 0:00:00\n",
      "Downloading keras-3.9.1-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 0.8/1.3 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 719.8 kB/s eta 0:00:00\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Downloading ml_dtypes-0.5.1-cp311-cp311-win_amd64.whl (209 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-5.29.4-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.0/5.5 MB 7.1 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.6/5.5 MB 3.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 2.4/5.5 MB 3.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 3.4/5.5 MB 3.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.5/5.5 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.5 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.5 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.5 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.5 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.5 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.5 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.5 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.5 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 1.8 MB/s eta 0:00:00\n",
      "Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------- ----------- 1.0/1.5 MB 6.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.3/1.5 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 2.6 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp311-cp311-win_amd64.whl (102 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.14.1-cp311-cp311-win_amd64.whl (305 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, urllib3, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, mdurl, MarkupSafe, markdown, idna, h5py, grpcio, google-pasta, gast, charset-normalizer, certifi, astunparse, absl-py, werkzeug, requests, markdown-it-py, tensorboard, rich, keras, tensorflow\n",
      "Successfully installed MarkupSafe-3.0.2 absl-py-2.2.1 astunparse-1.6.3 certifi-2025.1.31 charset-normalizer-3.4.1 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 idna-3.10 keras-3.9.1 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.5.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.14.1 protobuf-5.29.4 requests-2.32.3 rich-13.9.4 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.5.0 urllib3-2.3.0 werkzeug-3.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'method'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m x = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m y = np.array(output, dtype = \u001b[38;5;28mfloat\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: float() argument must be a string or a real number, not 'method'"
     ]
    }
   ],
   "source": [
    "x = np.array(input, dtype = float)\n",
    "y = np.array(output, dtype = float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\GEN AI\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([tf.keras.layers.Dense(2,activation = 'relu', input_shape = [1]),\n",
    "                             tf.keras.layers.Dense(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized data type: x=[1, 2, 3, 4, 5] (of type <class 'list'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = \u001b[32m0.01\u001b[39m), loss = \u001b[33m'\u001b[39m\u001b[33mmean_squared_error\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\GEN AI\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\GEN AI\\venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\__init__.py:125\u001b[39m, in \u001b[36mget_data_adapter\u001b[39m\u001b[34m(x, y, sample_weight, batch_size, steps_per_epoch, shuffle, class_weight)\u001b[39m\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m GeneratorDataAdapter(x)\n\u001b[32m    118\u001b[39m     \u001b[38;5;66;03m# TODO: should we warn or not?\u001b[39;00m\n\u001b[32m    119\u001b[39m     \u001b[38;5;66;03m# warnings.warn(\u001b[39;00m\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m#     \"`shuffle=True` was passed, but will be ignored since the \"\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    123\u001b[39m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized data type: x=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Unrecognized data type: x=[1, 2, 3, 4, 5] (of type <class 'list'>)"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.01), loss = 'mean_squared_error')\n",
    "model.fit(x,y,epochs = 100,verbose = 1)\n",
    "model.save(\"df.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'e': 1, 'h': 2, 'l': 3, 'p': 4}\n",
      "{1: 'e', 2: 'h', 3: 'l', 4: 'p'}\n"
     ]
    }
   ],
   "source": [
    "data = 'help'\n",
    "chars = sorted(list(set(data)))\n",
    "char2idx ={char: i+1 for i, char in enumerate(chars)}\n",
    "idx2char = {i+1: char for i, char in enumerate(chars)}\n",
    "print(char2idx)\n",
    "print(idx2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "seq_length = 3\n",
    "for i in range(len(chars) - seq_length):\n",
    "    seq = data[i:i + seq_length]\n",
    "    label = data[i + seq_length]\n",
    "    a = [char2idx[i] for i in seq]\n",
    "    x.append(a)\n",
    "    b = char2idx[label]\n",
    "    y.append(b)\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = len(data)+1\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\GEN AI\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "seq_length = 3\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = vocab,  output_dim = 5, input_length = seq_length, mask_zero=True))\n",
    "model.add(LSTM(10, activation = 'tanh', return_sequences = False))\n",
    "model.add(Dense(vocab, activation = 'softmax'))\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 1.0000 - loss: 1.6031\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 1.5992\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 1.5953\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 1.0000 - loss: 1.5913\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 1.5874\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 1.5833\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 1.5793\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 1.5753\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 1.5712\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 1.5670\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 1.5629\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 1.0000 - loss: 1.5587\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 1.0000 - loss: 1.5544\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 1.0000 - loss: 1.5501\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 1.5458\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 1.0000 - loss: 1.5414\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 1.0000 - loss: 1.5369\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 1.5324\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 1.5278\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 1.5232\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 1.5185\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 1.5137\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 1.0000 - loss: 1.5088\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 1.5039\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 1.0000 - loss: 1.4989\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 1.0000 - loss: 1.4938\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 1.0000 - loss: 1.4886\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 1.0000 - loss: 1.4833\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 1.0000 - loss: 1.4778\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 1.4723\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 1.4667\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 1.4610\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 1.4551\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 1.4491\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 1.4430\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 1.4368\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 1.0000 - loss: 1.4304\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 1.4238\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 1.4172\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 1.4103\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 1.4033\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 1.0000 - loss: 1.3962\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 1.0000 - loss: 1.3888\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 1.3813\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 1.3736\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 1.3657\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 1.3576\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 1.0000 - loss: 1.3494\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 1.3409\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 1.0000 - loss: 1.3321\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x29085fc0910>"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs = 50, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_21\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_21\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_20 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m5\u001b[0m)           │            \u001b[38;5;34m25\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_20 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m55\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,162</span> (8.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,162\u001b[0m (8.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">720</span> (2.81 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m720\u001b[0m (2.81 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,442</span> (5.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,442\u001b[0m (5.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 3]\n"
     ]
    }
   ],
   "source": [
    "input_seq = [\"h\", \"e\", \"l\"]  # Must be words from vocab\n",
    "input_idx = [char2idx[w] for w in input_seq]\n",
    "print(input_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 963ms/step\n",
      "Next word: p\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(np.array([input_idx]))\n",
    "a = np.argmax(pred)\n",
    "pred_word = idx2char[a]\n",
    "print(f\"Next word: {pred_word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to sequence prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In sequence-to-sequence (seq2seq) prediction, we predict an output sequence from an input sequence. For your character-level example (data = \"help\"), we'll\n",
    "# Train: Predict the next 3 characters from the first 3 characters\n",
    "# Input (X): ['h', 'e', 'l'] → Target (y): ['e', 'l', 'p']\n",
    "# Inference: Use the model to generate new sequences character-by-character.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = 'I am lucky to be in this world'\n",
    "data = data.lower()\n",
    "data = data.replace(\" \", \"\")  # Remove spaces for character-level modeling\n",
    "seq_length = 3\n",
    "\n",
    "# Create character mappings\n",
    "chars = sorted(list(set(data)))\n",
    "\n",
    "char2idx = {char: i+1 for i, char in enumerate(chars)}  # 0 reserved for padding\n",
    "idx2char = {i+1: char for i, char in enumerate(chars)}\n",
    "vocab_size = len(chars) + 1  # +1 for padding\n",
    "\n",
    "# Generate input (X) and target (y) sequences\n",
    "X = []\n",
    "y = []\n",
    "for i in range(len(data) - seq_length):\n",
    "    X.append([char2idx[char] for char in data[i:i+seq_length]])      # Input: [h, e, l]\n",
    "    y.append([char2idx[char] for char in data[i+1:i+1+seq_length]])  # Target: [e, l, p]\n",
    "\n",
    "X1 = np.array(X)  # Shape: (1, 3)\n",
    "y1 = np.array(y)  # Shape: (1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\GEN AI\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "seq_length = 3\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense,TimeDistributed\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = vocab_size,  output_dim = 5, input_length = seq_length, mask_zero=True))\n",
    "model.add(LSTM(10, activation = 'tanh', return_sequences = True))\n",
    "#TimeDistributed(Dense(vocab_size, activation='softmax'))\n",
    "model.add(Dense(vocab_size, activation = 'softmax'))\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - accuracy: 0.0167 - loss: 2.9451\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.0333 - loss: 2.9443\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.0667 - loss: 2.9435\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.0833 - loss: 2.9427\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.1000 - loss: 2.9419\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.1000 - loss: 2.9412\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.1000 - loss: 2.9404\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step - accuracy: 0.1000 - loss: 2.9396\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.0833 - loss: 2.9388\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.1000 - loss: 2.9380\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.1000 - loss: 2.9372\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.1167 - loss: 2.9364\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.1167 - loss: 2.9356\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.1167 - loss: 2.9348\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.1167 - loss: 2.9340\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.1167 - loss: 2.9331\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.1167 - loss: 2.9323\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.1167 - loss: 2.9315\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.1167 - loss: 2.9306\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.1167 - loss: 2.9297\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.1167 - loss: 2.9288\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.1167 - loss: 2.9279\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.1167 - loss: 2.9270\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.1167 - loss: 2.9261\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.1167 - loss: 2.9252\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.1167 - loss: 2.9242\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.1000 - loss: 2.9232\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.1000 - loss: 2.9222\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.1000 - loss: 2.9212\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.1000 - loss: 2.9202\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.1000 - loss: 2.9192\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.1000 - loss: 2.9181\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.1000 - loss: 2.9170\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - accuracy: 0.1000 - loss: 2.9159\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.1000 - loss: 2.9148\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - accuracy: 0.1000 - loss: 2.9137\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.1000 - loss: 2.9125\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.1000 - loss: 2.9113\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.1000 - loss: 2.9101\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.1000 - loss: 2.9088\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.1000 - loss: 2.9076\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.1000 - loss: 2.9063\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.1000 - loss: 2.9050\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.1000 - loss: 2.9036\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - accuracy: 0.1000 - loss: 2.9022\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.1000 - loss: 2.9008\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.1000 - loss: 2.8994\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.1000 - loss: 2.8979\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - accuracy: 0.1000 - loss: 2.8964\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.1000 - loss: 2.8949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x290ffd174d0>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X1, y1, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_20\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_20\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">95</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">209</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_19 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m5\u001b[0m)           │            \u001b[38;5;34m95\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_19 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m10\u001b[0m)          │           \u001b[38;5;34m640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m19\u001b[0m)          │           \u001b[38;5;34m209\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,834</span> (11.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,834\u001b[0m (11.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">944</span> (3.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m944\u001b[0m (3.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,890</span> (7.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,890\u001b[0m (7.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction:\n",
      "[9, 16, 3]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "[16, 3, 15]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
      "[3, 15, 15]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n",
      "[15, 15, 15]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
      "[15, 15, 15]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "[15, 15, 15]\n",
      "Seed: \"luc\" → Prediction: \"ttttt\"\n"
     ]
    }
   ],
   "source": [
    "def predict_seq(seed, predict_length=5):\n",
    "    seed = seed.lower().replace(\" \", \"\")\n",
    "    if len(seed) < seq_length:\n",
    "        raise ValueError(f\"Seed needs at least {seq_length} characters\")\n",
    "    \n",
    "    # Convert seed to indices\n",
    "    seq = [char2idx[c] for c in seed[:seq_length]]\n",
    "    print(seq)\n",
    "    generated = \"\"\n",
    "    \n",
    "    for _ in range(predict_length):\n",
    "        # Predict next character probabilities for all positions\n",
    "        probs = model.predict(np.array([seq]))[0] #shape: (seq_length, vocab_size)\n",
    "        #print(probs)  # Shape: (seq_length, vocab_size)\n",
    "        \n",
    "        # Take the last prediction (for autoregressive generation)\n",
    "        next_char_idx = np.argmax(probs[-1])  # Last timestep's prediction\n",
    "        next_char = idx2char[next_char_idx]\n",
    "        generated += next_char\n",
    "\n",
    "        # Update sequence (sliding window)\n",
    "        seq = seq[1:] + [next_char_idx]\n",
    "        print(seq)\n",
    "    print(f'Seed: \"{seed}\" → Prediction: \"{generated}\"')\n",
    "\n",
    "# Test\n",
    "print(\"\\nPrediction:\")\n",
    "predict_seq(\"luc\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iamluckytobeinthisworld'"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'h': 6,\n",
       " 'i': 7,\n",
       " 'k': 8,\n",
       " 'l': 9,\n",
       " 'm': 10,\n",
       " 'n': 11,\n",
       " 'o': 12,\n",
       " 'r': 13,\n",
       " 's': 14,\n",
       " 't': 15,\n",
       " 'u': 16,\n",
       " 'w': 17,\n",
       " 'y': 18}"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
